## CloudFormation

Started off CloudFormation with a guest instructor __Rohini Gaonkar, an AWS Sr. Dev__ Advocate leading instruction along with Andrew. We walked through setting up a basic CloudFormation template deploying an ECS Cluster. We also created a deploy script that deployed the cluster, along with a new S3 bucket named cfn-artifacts-1. In addition to this, we add a task to our .gitpod.yml file to install cfn-lint. Per ChatGPT, "cfn-lint is a tool used for linting CloudFormation templates, which checks for syntactical errors, best practices, and adherence to standards. It ensures the correctness and quality of the CloudFormation template."

![Screenshot 2024-03-03 050143](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/07dbf30e-5cfb-4b6c-8759-4502f195de08)

![Screenshot 2024-03-03 050154](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/49bca862-3f22-44dc-ae42-c691c69064d0)

![Screenshot 2024-03-03 051136](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/d54e182c-fe8c-4ece-a9b1-671ccb48d369)


![Screenshot 2024-03-03 071652](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/0d9a8d2e-2868-4bd3-bb0b-b2a42e8b194b)

![Screenshot 2024-03-03 172132](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/5b24d319-f257-4cce-9f28-c6f2db3d86bd)

![Screenshot 2024-03-03 221205](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/49602e32-4812-4abd-9159-0268203e477d)



AWS CloudFormation is a service that provides a way to model and set up your AWS resources using templates. With CloudFormation, you can describe the resources you need and their dependencies in a JSON or YAML file, and AWS handles the provisioning and configuration, ensuring consistency and scalability across your infrastructure. This approach enables infrastructure management through code, streamlining deployment and simplifying updates and rollback processes.



In AWS CloudFormation, the networking layer refers to the configuration and management of network-related resources such as Virtual Private Clouds (VPCs), subnets, route tables, security groups, and network access control lists (ACLs). This layer enables you to define the network infrastructure necessary for your applications, including the setup of private and public subnets, internet gateways, NAT gateways, and VPN connections. By specifying networking configurations in your CloudFormation templates, you can ensure consistent and secure network setups across your AWS environment, facilitating communication between different components of your applications while adhering to best practices for network isolation and security.


```

In AWS CloudFormation (CFN), the following are commonly used intrinsic functions:

!Ref: Retrieves the value of a parameter or a resource.
!Sub: Substitutes variables in a string with values you specify.
!GetAtt: Retrieves the value of an attribute from a resource in the template.
!Join: Combines a list of strings into a single string, using a specified delimiter.
!Select: Returns a single object from a list of objects by index.
!FindInMap: Returns the value corresponding to keys in a two-level map.
!Split: Splits a string into a list of string values.
!ImportValue: Imports the value of an exported output from another CloudFormation stack.
!Condition: Specifies a conditional statement in the template.
!Transform: Applies a macro or transformation to the template.
These functions allow you to dynamically manipulate and reference values within CloudFormation templates.
```


# Networking Layer

Moving onto main instruction, we now have a cfn folder created in aws directory. We create a new folder within this directory named networking. Next we create a new file in this folder named template.yaml. We begin, just fleshing out the template.yaml, commenting what we're going to need.

```
AWSTemplateFormatVersion: 2010-09-09

# VPC
# IGW
# Route Tables
# Subnets
# Subnet A
# Subnet B
# Subnet C
```

- VPC: Defines a virtual network environment in AWS where your AWS resources can be launched. It provides isolation and security.

- IGW (Internet Gateway): A gateway that allows communication between instances in your VPC and the internet.

- Route Tables: Specifies the rules for routing traffic within the VPC, determining where network traffic is directed.

- Subnets: Segments of a VPC's IP address range that you can divide to host your resources. They allow you to organize resources and control access within your VPC. Subnet A, B, and C are specific subdivisions within the VPC.



We immediately consult AWS documentation for the VPC, which in CloudFormation is known as AWS::EC2::VPC.
https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-vpc.html
```
AWSTemplateFormatVersion: 2010-09-09

# VPC
Resources:
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock:
      EnableDnsHostnames: true
      EnableDnsSupport: true
      InstanceTenancy: default
# IGW
# Route Tables
# Subnets
# Subnet A
# Subnet B
# Subnet C
```
  
   
CIDR (Classless Inter-Domain Routing) notation is based on binary mathematics. An IP address consists of 32 bits (for IPv4) or 128 bits (for IPv6). In CIDR notation, a network is represented by an IP address followed by a forward slash and a number, which indicates the length of the network prefix.

For the example "192.168.0.0/24":

The network portion consists of the first 24 bits, which are fixed as "192.168.0".
The remaining 8 bits are available for addressing hosts.
To find the range of addresses, we can vary the values of the last octet (8 bits) from 0 to 255:

The range of addresses would be from "192.168.0.0" to "192.168.0.255".
This gives a total of 256 addresses (from 0 to 255) within the specified CIDR range.
  
  
    

In our ./bin/cfn directory, we create a new script named networking-deploy.

Cloudformation deploy command.
Deploys the specified AWS CloudFormation template by creating and then executing a change set. The command terminates after AWS CloudFormation executes the change set. If you want to view the change set before AWS CloudFormation executes it, use the --no-execute-changeset flag.

```
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/networking/template.yaml"

cfn-lint $CFN_PATH 

aws cloudformation deploy \
    --stack-name "Cruddur" \
    --s3-bucket $CFN_BUCKET \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --capabilities CAPABILITY_NAMED_IAM

```
  
  
  
We set the value for a variable named CFN_PATH to the path for our template.yaml file for our network layer.
Here are the options and arguments used:

--stack-name: Specifies the name of the stack to create or update. In this case, it's set to "Cruddur".

--s3-bucket: Specifies the S3 bucket to upload the CloudFormation template to. The value of the CFN_BUCKET variable is expected to be set somewhere else in the script or in the environment.

--template-file: Specifies the path to the CloudFormation template file, which is set to the value of the CFN_PATH variable.

--no-execute-changeset: Indicates that the changeset created during the deployment should not be executed immediately. It allows you to review the changes before applying them.

--capabilities CAPABILITY_NAMED_IAM: Specifies the IAM capabilities required to create or update IAM resources in the CloudFormation stack. This capability is necessary when the template includes IAM resources.

The following IAM resources require you to specify either the CAPABILITY_IAM or CAPABILITY_NAMED_IAM capability:

- If you have IAM resources, you can specify either capability.
- If you have IAM resources with custom names, you must specify CAPABILITY_NAMED_IAM.
- If you don't specify either of these capabilities, AWS CloudFormation returns an InsufficientCapabilities error.


```
export CFN_BUCKET="cfn-artifacts-1"
gp env CFN_BUCKET="cfn-artifacts-1"
```

![Screenshot 2024-03-03 082041](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/e7260560-ec95-4159-8f3c-8116e6a3ea11)

![Screenshot 2024-03-03 221621](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/16797595-d82e-452b-a9ef-a2f034c32919)

  
  
We have yet to fill in a value for the CidrBlock property in our networking template.yaml file.  https://cidr.xyz to determine what we'll use for our CIDR block for our VPC. this will determine the range of IP addresses that can be assigned to the resources within our VPC and also help us maintain higher availability of our resources.

![Screenshot 2024-03-11 145218](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/e92687d3-a0be-44e0-b1df-018bf64b87b1)

```
AWSTemplateFormatVersion: 2010-09-09

Resources: 
  VPC:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-vpc.html
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsHostnames: true
      EnableDnsSupport: true
      InstanceTenancy: default
```

![Screenshot 2024-03-04 145742](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/48254ca0-76d7-41e6-9294-50e5124f730a)
  
  
  
When the VPC completes, we found that AWS also automatically creates a route table for you. In sifting through the resources, we had a bit of trouble with our previous configuration resources showing in the console. To remedy this, we decide to name the VPC resource as well, so we add tags to our template.yaml.

```
 Tags:
        - Key: Name
          Value: CruddurVPC
```

This will name our VPC resource as CruddurVPC.




The next resource we must create is an internet gateway. We go back to AWS documentation and look specifically for AWS::EC2::InternetGateway. There's no properties to set for an internet gateway other than tags, so we implement the code:



```
  IGW:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-internetgateway.html
    Type: AWS::EC2::InternetGateway        #Allocates an internet gateway for use with a VPC. After creating the Internet gateway, you then attach it to a VPC.
    Properties: 
      Tags:
        - Key: Name
          Value: CruddurIGW
```
  
  
  
  
When we create an internet gateway, we also must tell our CFN template to attach it. We consult AWS documentation for AWS::EC2::VPCGatewayAttachment then begin specifying properties.

```
  AttachIGW:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref VPC
      InternetGatewayId: !Ref IGW
```
  
  
  
   
You’ll note the __!Ref function__ being used here. !Ref VPC and !Ref IGW are used for the VpcId and InternetGatewayId properties respectively to reference the VPC and IGW resources defined earlier in the template.
  
  
![ref](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/e30194f5-9249-4832-898d-11c66f3caec1)

     
Implementing a route table, which is responsible for directing network traffic for our VPC.
  
```yaml
  RouteTable:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-routetable.html
    Type: AWS::EC2::RouteTable   #Specifies a route table for the specified VPC. After you create a route table, you can add routes and associate the table with # a subnet.
    Properties:
      VpcId: !Ref VPC 
      Tags:
        - Key: Name
          Value: CruddurRT
```

   
Attaching an IGW establishes the physical link between the VPC and the internet.
Configuring routes in the VPC's route table defines the logical routing rules for traffic, including directing internet-bound traffic through the IGW.
Both steps are essential for enabling internet connectivity for resources within the VPC.

When you attach an internet gateway to a VPC in AWS, the internet gateway itself is indeed already configured to handle traffic to and from the internet. However, merely attaching the internet gateway to the VPC does not automatically route all traffic destined for the internet to that gateway. Instead, you need to configure the routing within the VPC's route table to direct internet-bound traffic to the internet gateway.

By default, a VPC's route table does not have a route that forwards internet-bound traffic (0.0.0.0/0) to the internet gateway. Therefore, after attaching the internet gateway to the VPC, you must add a route to the VPC's route table that points internet-bound traffic to the internet gateway. This route tells the VPC where to send traffic destined for the internet.

  
Next, we implement a route:

```yaml
  RouteToIGW:
    # [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-route.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-route.html)
    Type: AWS::EC2::Route
    DependsOn: AttachIGW
    Properties:
      RouteTableId: !Ref RouteTable
      GatewayId: !Ref IGW
      DestinationCidrBlock: 0.0.0.0/0
```

The GatewayId specifies the Internet Gateway (IGW) as the target for the traffic matching the DestinationCidrBlock. This means that any traffic destined for IPs outside of the VPC's CIDR block will be sent to the IGW for further routing towards the internet.


Please bring your attention to the DependsOn property. This property indicates that RouteToIGW will not be created if AttachIGW does not exist. So if our gateway is not created, CloudFormation will not create our route either. The GatewayId property is returning the logical id of the internet gateway we'd like to use, so we point it towards our IGW gateway. We want our route going out to the internet, so we set the DestinationCidrBlock to 0.0.0.0/0. The reasoning is, 0.0.0.0/0 represents the entire IPv4 address space in CIDR notation.


We also implement a route for local as well, but we’re uncertain on the GatewayId:

```
  RouteToLocal:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-route.html
    Type: AWS::EC2::Route
    DependsOn: AttachIGW
    Properties:
      RouteTableId: !Ref RouteTable
      GatewayId: "local"
      DestinationCidrBlock: 10.0.0.0/16
```
  
  
  
![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/10759a5a-0f25-4641-8049-2d96862aca35)

Error received: "The route identified by 10.0.0.0/16 already exists."
Action taken: Commented out route creation code, deleted CloudFormation stack in ROLLBACK_COMPLETE state, redeployed with VPC, internet gateway, and gateway attachment only.

Observation: Network ACL created automatically. NACLs act as stateless firewalls for subnet-level traffic control.
Tip: Ensure NACLs have outbound routes to avoid blocking internet access.


We uncomment the lines of code creating our route table and our RouteToIGW. Then, we again deploy our networking CFN template. When the changeset is created, we execute it from CFN. When we go back to EC2 to view our our new route table, it automatically created the route to local as well:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/5d64a896-4151-45c0-b9c3-13ee659418c0)


Since the route to local is already being created, we remove the commented lines of code creating that route. Next, we must create our subnets. We might decide that our database must sit privately, so in addition to our public subnets, we create private ones as well.


```
  SubnetPub1:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnet.html
    Type: AWS::EC2::Subnet
    Properties:
      AssignIpv6AddressOnCreation: false
      AvailabilityZone: us-east-1a
      CidrBlock: 10.0.0.0/24
      EnableDns64: false
      MapPublicIpOnLaunch: true # public subnet
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: CruddurSubnetPub1

  SubnetPub2:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnet.html
    Type: AWS::EC2::Subnet
    Properties:
      AssignIpv6AddressOnCreation: false
      AvailabilityZone: us-east-1b
      CidrBlock: 10.0.4.0/24
      EnableDns64: false
      MapPublicIpOnLaunch: true # public subnet
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: CruddurSubnetPub2  
  SubnetPub3:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnet.html
    Type: AWS::EC2::Subnet
    Properties:
      AssignIpv6AddressOnCreation: false
      AvailabilityZone: us-east-1c
      CidrBlock: 10.0.8.0/24
      EnableDns64: false
      MapPublicIpOnLaunch: true # public subnet
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: CruddurSubnetPub3
  SubnetPriv1:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnet.html
    Type: AWS::EC2::Subnet
    Properties:
      AssignIpv6AddressOnCreation: false
      AvailabilityZone: us-east-1a
      CidrBlock: 10.0.12.0/24
      EnableDns64: false
      MapPublicIpOnLaunch: false # private subnet
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: CruddurSubnetPriv1  
  SubnetPriv2:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnet.html
    Type: AWS::EC2::Subnet
    Properties:
      AssignIpv6AddressOnCreation: false
      AvailabilityZone: us-east-1b
      CidrBlock: 10.0.16.0/24
      EnableDns64: false
      MapPublicIpOnLaunch: false # private subnet
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: CruddurSubnetPriv2
  SubnetPriv3:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnet.html
    Type: AWS::EC2::Subnet
    Properties:
      AssignIpv6AddressOnCreation: false
      AvailabilityZone: us-east-1c
      CidrBlock: 10.0.20.0/24
      EnableDns64: false
      MapPublicIpOnLaunch: false # private subnet
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: CruddurSubnetPriv3 
```

A few key takeaways from these properties:

AssignIpv6AddressOnCreation: controls whether IPV6 addresses are automatically assigned to instances that are launched in the subnet

AvailabilityZone: the availability zone within AWS that our subnet is created in

EnableDns64: controls whether DNS64 is enabled for an IPv6 enabled subnet. Since we're not using IPv6, this value is false

MapPublicIpOnLaunch: controls the automatic assignment of a public IP address to instances launched within a subnet. Notice our public subnets have this set to true, where our private ones are set to false.

Next we must implement our SubnetRouteTableAssocation resources. This will associate our subnets with our route table in the VPC.

```
SubnetPub1RTAssociation:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnetroutetableassociation.html
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref SubnetPub1
      RouteTableId: !Ref RouteTable  
  SubnetPub2RTAssociation:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnetroutetableassociation.html  
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref SubnetPub2
      RouteTableId: !Ref RouteTable  
  SubnetPub3RTAssociation:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnetroutetableassociation.html  
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref SubnetPub3
      RouteTableId: !Ref RouteTable  
  SubnetPriv1RTAssociation:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnetroutetableassociation.html  
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref SubnetPriv1
      RouteTableId: !Ref RouteTable  
  SubnetPriv2RTAssociation:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnetroutetableassociation.html  
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref SubnetPriv2
      RouteTableId: !Ref RouteTable  
  SubnetPriv3RTAssociation:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-subnetroutetableassociation.html  
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref SubnetPriv3
      RouteTableId: !Ref RouteTable
```

With this completed, we now try to deploy our template.yaml for our networking layer again. This time, cfn-lint gives us some feedback.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/9238db89-30a9-46c6-bb2e-b9c7d38a3a8d)

To circumvent these warnings, we go ahead and pass some parameters in our networking template.
```
Parameters:
  Az1:
    Type: AWS::EC2::AvailabilityZone::Name
    Default: us-east-1a
  Az2:
    Type: AWS::EC2::AvailabilityZone::Name
    Default: us-east-1b
  Az3:
    Type: AWS::EC2::AvailabilityZone::Name
    Default: us-east-1c
```

Then we use the !Ref function to pass the values in our template, per subnet. For example:

```
AvailabilityZone: !Ref Az1
```

We again deploy the CFN template, this time the changeset is created. We execute it via AWS. The create fails this time, stating the IPv6CidrBlock cannot be empty. We review AWS documentation to see why.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/b2e8ddf7-8cf9-4c21-895c-219b718012a7)


Per the snippet above, since we specified AssignIpv6AddressOnCreation, we must also specify Ipv6CidrBlock. Since neither is being used, we just remove the AssignIpv6AddressOnCreation property from our template. With the template file updated, we again run our networking-deploy script. We execute the changeset from CloudFormation and we have an UPDATE_COMPLETE status.

![Screenshot 2024-03-04 150018](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/4980f762-3559-4c19-87e1-b37c9cdaa5a0)


we’re not going to implement security groups at this layer, because security groups are usually around particular services. We also decide we want to clean things up in our code a little bit, particularly our CidrBlock properties. We do this by implementing some parameters:

```
Parameters:
  SubnetCidrBlocks: 
    Description: "Comma-delimited list of CIDR blocks for our private public subnets"
    Type: CommaDelimitedList
    Default: > 
      10.0.0.0/24, 
      10.0.4.0/24, 
      10.0.8.0/24, 
      10.0.12.0/24, 
      10.0.16.0/24, 
      10.0.20.0/24   
```
  

  
You’ll note that we’re using a Comma Delimited List for our SubnetCidrBlocks parameter. Andrew explains how we're implementing this by using what's known as a scalar variable in Yaml.
  
A scalar is a variable that holds one value at a time. Scalars are generally primitive data types e.g. String, Int, Bool". We're using what's known as a folded block scalar style, using the folded start with a >. This allows CloudFormation to treat our parameter as a single string.
  
  
    
We’re able to reference these values for our CidrBlock property by using the !Select function.
```
CidrBlock: !Select [0, !Ref SubnetCidrBlocks]
```



In the above code snippet, we’re selecting the first element from the list of subnet CIDR blocks, i.e. 10.0.0.0/24.

We also add a parameter for our VPC CidrBlock property as well.
```
Parameters:
  VpcCidrBlock:
    Type: String
    Default: 10.0.0.0/16
```



    

We then pass the value of the parameter to the property using the !Ref function.

```
Resources: 
  VPC:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-vpc.html
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: !Ref VpcCidrBlock
```
  
  
  
        
From there, we update the tags for all of our resources that have them in our template.yaml to utilize pseudo parameters from AWS, in this instance, the AWS::StackName parameter for our VPC. 
https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/pseudo-parameter-reference.html

```
 Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName}VPC"
```



    
Adding outputs will allow us to expose information about our resources created by the stack. We'll be able to use these outputs for other stacks when we implement future layers.


```
Outputs:
  VpcId:
    Value: !Ref VPC
    Export:
      Name: VpcId
  VpcCidrBlock:
    Value: !GetAtt VPC.CidrBlock
    Export:
      Name: VpcCidrBlock
  SubnetCidrBlocks:
    Value: !Join [",", !Ref SubnetCidrBlocks]
    Export:
      Name: SubnetCidrBlocks
  SubnetIds: 
    Value: !Join 
      - "," 
      - - !Ref SubnetPub1 
        - !Ref SubnetPub2 
        - !Ref SubnetPub3 
        - !Ref SubnetPriv1
        - !Ref SubnetPriv2
        - !Ref SubnetPriv3
    Export: 
      Name: SubnetIds
  AvailabilityZones:
    Value: !Join 
      - "," 
      - - !Ref Az1
        - !Ref Az2
        - !Ref Az3  
    Export: 
      Name: AvailabilityZones
```

Let’s breakdown each output:

VpcId: This output references the VPC resource using !Ref VPC. It exports the value with the name VpcId. This output can be referenced in other stacks to retrieve the VPC ID.

VpcCidrBlock: This output uses the !GetAtt function to retrieve the CidrBlock attribute of the VPC resource. It exports the value with the name VpcCidrBlock. This output provides the CIDR block of the VPC.

SubnetCidrBlocks: This output uses the !Join function to concatenate the values of SubnetCidrBlocks, which are referenced by !Ref SubnetCidrBlocks, separated by commas. It exports the joined value with the name SubnetCidrBlocks. This output provides a comma-separated list of subnet CIDR blocks.

SubnetIds: This output uses the !Join function to concatenate the values of SubnetPub1, SubnetPub2, SubnetPub3, SubnetPriv1, SubnetPriv2, and SubnetPriv3 separated by commas. The subnet values are obtained using !Ref for each subnet. It exports the joined value with the name SubnetIds. This output provides a comma-separated list of subnet IDs.

AvailabilityZones: This output uses the !Join function to concatenate the values of Az1, Az2, and Az3 separated by commas. The availability zone values are obtained using !Ref for each availability zone. It exports the joined value with the name AvailabilityZones. This output provides a comma-separated list of availability zones.

When we again deploy then execute the changeset from CloudFormation, we now have Outputs available under the Outputs tab.

![Screenshot 2024-03-04 150926](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/3bb541a5-bcbe-4a8b-ba83-cd85e770a25d)

![Screenshot 2024-03-04 180827](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/ecb74429-aff1-4b8b-b06e-053128d72f21)




# Cluster Layer

Next, we are going to implement our Cluster layer to define our Fargate cluster.

```
AWSTemplateFormatVersion: 2010-09-09

# Parameters:
Resources:
  ECSCluster: #LogicalName
    Type: 'AWS::ECS::Cluster'
    Properties:
      ClusterName: MyCluster1
      CapacityProviders:
        - FARGATE
# Outputs:
```

You can see we’re creating an ECS Cluster resource. We continue on with this, adding properties for the cluster:

```
AWSTemplateFormatVersion: 2010-09-09

# Parameters:
Resources:
  FargateCluster:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ecs-cluster.html 
    Type: AWS::ECS::Cluster
    Properties: 
      ClusterName: !Sub "${AWS::StackName}FargateCluster"
      CapacityProviders: 
        - FARGATE 
      ClusterSettings: 
        - Name: containerInsights
          Value: enabled
      Configuration: 
        ExecuteCommandConfiguration:
          Logging: DEFAULT
      ServiceConnectDefaults: 
        Namespace: cruddur
# Outputs:
```

Some information on the properties of the cluster:

CapacityProviders: This property specifies the capacity providers to associate with the cluster. In this case, it has a single value FARGATE, indicating that the cluster should use AWS Fargate capacity provider.

ClusterSettings: This property allows you to configure additional settings for the cluster. In this case, it specifies a setting named containerInsights with the value enabled, enabling the CloudWatch Container Insights feature.

Configuration: This property allows you to specify additional configurations for the cluster. Here, it includes the ExecuteCommandConfiguration property with Logging set to DEFAULT, which configures the default logging behavior for execute command functionality.

ServiceConnectDefaults: This property allows you to specify a default Service Connect namespace. Once the default namespace is set, any new services with Service Connect turned on that are created in the cluster are added as client service in the namespace. We set the Namespace property to cruddur.

While working through AWS documentation for this, we come upon the Description section and decide to go back and add this to our networking layer template.yaml.



We begin working on the cluster-deploy script now as well by copying our networking-deploy script as a start off point, then editing it down.

```
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/cluster/template.yaml"

cfn-lint $CFN_PATH 

aws cloudformation deploy \
    --stack-name "Cruddur" \
    --s3-bucket $CFN_BUCKET \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --tags group="cruddur-cluster" \
    --capabilities CAPABILITY_NAMED_IAM
```

You’ll notice the CFN_PATH is now updated to the path for our cluster template.yaml file, and we're also propagating down tags from the CloudFormation commands. We go back to our networking-deploy script and implement the tags there as well. Then, we move forward with implementing our cluster layer through the template.yaml. We add an application load balancer.

```
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-loadbalancer.html
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: !Sub "${AWS::StackName}ALB"
      Type: application
      IpAddressType: ipv4
      # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-elasticloadbalancingv2-loadbalancer-loadbalancerattributes.html
      Scheme: internet-facing
      SecurityGroups: 
        - security group ids
      Subnets: 
      LoadBalancerAttributes: 
        - Key: routing.http2.enabled
          Value: true
        - Key: routing.http.preserve_host_header.enabled
          Value: false
        - Key: deletion_protection.enabled
          Value: true
        - Key: load_balancing.cross_zone.enabled
          Value: true
        - Key: access_logs.s3.enabled
          Value: false
          # In case we want to turn on logs
        # - Key: access_logs.s3.bucket
          # Value: bucket-name
        # - Key: access_logs.s3.prefix
          # Value: ""
```


Remember that we have left the Subnets property blank for now. More details on the properties we're setting here:

Type: Indicates the type of load balancer. In this case, it is set to application, which represents an application load balancer.

IpAddressType: Specifies the IP address type for the ALB. Here, it is set to ipv4, indicating the use of IPv4 addresses. It is the most common choice and allows the ALB to handle traffic over IPv4. The other option we could've selected is dualstack. This option specifies that the ALB should use both IPv4 and IPv6 addresses. It enables the ALB to handle traffic over both IPv4 and IPv6 protocols

LoadBalancerAttributes: Specifies a list of load balancer attributes and their corresponding values. Each attribute is represented as a dictionary with a Key and Value pair.
 
 
 
 
Key: routing.http2.enabled: Enables HTTP/2 routing for the ALB.

When you define HTTP/2 as enabled in CloudFormation for an ALB (Application Load Balancer), you are specifically configuring it for communication between the ALB and the clients (such as web browsers or other HTTP clients).



Key: routing.http.preserve_host_header.enabled: Enables preserving the host header for HTTP routing. When set to false, the host header is not preserved when forwarding requests to the target groups.

Key: deletion_protection.enabled: Enables deletion protection for the ALB. When deletion protection is enabled, the ALB cannot be deleted accidentally.

Key: load_balancing.cross_zone.enabled: Enables cross-zone load balancing. When enabled, the ALB evenly distributes traffic across all availability zones specified in the subnets property.

Key: access_logs.s3.enabled: Enables access logs to be stored in Amazon S3. When set to false, no access logs will be generated and stored.

We also commented out a couple of lines of code that would enable logging of our S3 bucket with a name value given by us, which would capture detailed information about every request made to the bucket, such as the requester’s IP address, the time of the request, the HTTP status code, and more. The access_logs.s3.prefix property specifies a prefix or a directory within the access logging S3 bucket where the logs should be stored. By using a prefix, you can organize and categorize the logs based on specific criteria, such as by date, requester, or any other relevant information.

Also notice that our SecurityGroups property does not have a valid value yet. We must create our security groups as well to reference the logical ID of the SG. We continue on with fleshing out the cluster template, adding a Descritpion field to the template.

```
Description: |
  The networking and cluster configuration to support Fargate containers:
  - ECS Fargate Cluster
  - Application Load Balancer (ALB)
    -IPv4 only
    - internet facing
  - ALB Security Group
  - HTTPS Listener
    - send root domain to frontend Target Group
    - send API subdomain to backend Target Group
  - HTTP Listener
    - redirects to HTTPS Listener
  - Backend Target Group
  - Frontend Target Group
```


A Description field in a CFN template provides an overview of what the template does. It's not mandatory for a CFN template, but it is considered a good practice to include it, as it can help other team members, stakeholders, or reviewers understand the purpose and functionality of the template.

Before we implement security groups, we must add the listeners for our HTTP and HTTPS. As noted in our Description, the HTTPS Listener will send HTTPS requests from our ALB to our frontend target group and send API requests to our backend target group. The HTTP listener will redirect to the HTTPS listener.

```
  HTTPSListener:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-listener.html
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      Protocol: HTTPS    
      Port: 443
      LoadBalancerArn: !Ref ALB           
      Certificates: 
        - CertificateArn: !Ref CertificateArn
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref FrontendTG
  HTTPListener: 
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-listener.html
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      Protocol: HTTP
      Port: 80
      LoadBalancerArn: !Ref ALB        
      DefaultActions:
        - Type: redirect
          RedirectConfig:
            Protocol: "HTTPS"
            Port: 443
            Host: "#{host}"
            Path: "/#{path}"
            Query: "#{query}"
```

For our HTTPSListener:

Protocol: Sets the listener's protocol to HTTPS, indicating that it will handle incoming HTTPS traffic.
Port: Defines the port number on which the listener will listen for HTTPS requests (port 443 in this case).
LoadBalancerArn: Refers to the ARN of the ALB to which the listener will be attached.
Certificates: Specifies the SSL/TLS certificate to be used for encrypting and decrypting HTTPS traffic. It references the certificate ARN using the !Ref intrinsic function.
DefaultActions: Defines the default action to be taken by the listener when it receives a request. In this case, it is set to forward the request to a target group referenced by FrontendTG, which we will define a bit further down.
  
  
For our HTTPListener:

DefaultActions: Defines the default action to be taken by the listener when it receives a request. In this case, it is set to redirect the request to HTTPS using the specified RedirectConfig.
Type: Specifies the action type as "redirect".
RedirectConfig: Provides configuration options for the redirect action, including the target protocol (HTTPS), port (443), host, path, query, and status code (HTTP_301 indicating a permanent redirect).
The Host, Path, and Query properties in the RedirectConfig section of the HTTPListener resource define how the incoming request's host, path, and query parameters are preserved during the HTTP to HTTPS redirection.


We’re passing a parameter as the value for CertificateArn. The parameter is called CertificateArn, so we add this as a parameter as well.
```
Parameters:
  CertificateArn:
    Type: String
```





From here, we add our application load balancer security group, or ALBSG.

```
  ALBSG:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-security-group.html
    Type: AWS::EC2::SecurityGroup
    Properties: 
      GroupName: !Sub "${AWS::StackName}AlbSG"
      GroupDescription: Public Facing SG for our Cruddur ALB
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: '0.0.0.0/0'
          Description: INTERNET HTTPS
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '0.0.0.0/0'
          Description: INTERNET HTTP
```

The properties defined here GroupName and GroupDescription sets the name and provides a description of the security group. The name cannot start with "sg" and the GroupDescription is a required property. There's a couple rules set in the SecurityGroupIngress property that I'll explain further:

The first rule allows TCP traffic on port 443 (HTTPS) from any source IP (0.0.0.0/0) and provides a description indicating that it is for internet HTTPS traffic.

```
     - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: '0.0.0.0/0'
          Description: INTERNET HTTPS
```

The second rule allows TCP traffic on port 80 (HTTP) from any source IP (0.0.0.0/0) and provides a description indicating that it is for internet HTTP traffic.
```
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '0.0.0.0/0'
          Description: INTERNET HTTP
```

With our security group defined, we can now go back to our load balancer to define the security group property:
```
 ALB:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-loadbalancer.html
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: !Sub "${AWS::StackName}ALB"
      Type: application
      IpAddressType: ipv4
      # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-elasticloadbalancingv2-loadbalancer-loadbalancerattributes.html
      Scheme: internet-facing
      SecurityGroups: 
        - !Ref ALBSG
```


We must add an additional rule for our HTTPS Listener to redirect API requests to our backend target group, which we've yet to define as well. To do this, we add a Listener Rule.


#### It is a listener __rule__ which is set for https listener
```
ApiALBListenerRule:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-listenerrule.html
    Type: AWS::ElasticLoadBalancingV2::ListenerRule
    Properties:
      Conditions: 
        - Field: host-header
          HostHeaderConfig: 
            Values: 
              - api.gooddesignsolutions.in
      Actions: 
        - Type: forward
          TargetGroupArn: !Ref BackendTG
      ListenerArn: !Ref HTTPSListener
      Priority: 1
```

Here’s a further breakdown of our properties:

Conditions: Specifies the conditions that must be met for the rule to be applied.

Field: Sets the condition field to "host-header", which means the rule will be applied based on the value of the host header in the incoming request. The host header indicates the specific host or domain the HTTP request wants to communicate with. The host header allows the server to identify which virtual host or website the client is targeting when multiple websites or applications are hosted on the same server.

HostHeaderConfig: Specifies the configuration for the host header condition.

Values: Sets the expected value for the host header to api.thejoshdev.com. The rule will match requests with this host-header value.

The Actions properties forwards the requests that are matched with the host-header set in our Conditions, in this case, api.gooddesignsolutions.in and forwards them to the BackendTG target group, which we still need to define.

The Priority property sets the priority of the rule to 1, which determines the order of rules to be evaluated. The lower the number, the higher the priority.


```

BackendTG:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-targetgroup.html
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties: 
      Name: !Sub "${AWS::StackName}BackendTG"
      Port: !Ref BackendPort
      HealthCheckEnabled: true      
      HealthCheckProtocol: !Ref BackendHealthCheckProtocol         
      HealthCheckIntervalSeconds: !Ref BackendHealthCheckIntervalSeconds
      HealthCheckPath: !Ref BackendHealthCheckPath
      HealthCheckPort: !Ref BackendHealthCheckPort
      HealthCheckTimeoutSeconds: !Ref BackendHealthCheckTimeoutSeconds
      HealthyThresholdCount: !Ref BackendHealthyThresholdCount
      UnhealthyThresholdCount: !Ref BackendUnhealthyThresholdCount
      IpAddressType: ipv4
      Matcher: 
        HttpCode: 200
      Protocol: HTTP
      ProtocolVersion: HTTP2
      TargetGroupAttributes: 
        - Key: deregistration_delay.timeout_seconds
          Value: 0
      VpcId: CROSS_REFERENCE_STACK    
  FrontendTG:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-targetgroup.html
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties: 
      Name: !Sub "${AWS::StackName}FrontendTG"
      Port: !Ref FrontendPort
      HealthCheckEnabled: true      
      HealthCheckProtocol: !Ref FrontendHealthCheckProtocol         
      HealthCheckIntervalSeconds: !Ref FrontendHealthCheckIntervalSeconds
      HealthCheckPath: !Ref FrontendHealthCheckPath
      HealthCheckPort: !Ref FrontendHealthCheckPort
      HealthCheckTimeoutSeconds: !Ref FrontendHealthCheckTimeoutSeconds
      HealthyThresholdCount: !Ref FrontendHealthyThresholdCount
      UnhealthyThresholdCount: !Ref FrontendUnhealthyThresholdCount
      IpAddressType: ipv4
      Matcher: 
        HttpCode: 200
      Protocol: HTTP
      ProtocolVersion: HTTP2
      TargetGroupAttributes: 
        - Key: deregistration_delay.timeout_seconds
          Value: 0
      VpcId: CROSS_REFERENCE_STACK
```

Some key takeaways from the properties we defined for our target groups that I haven’t referenced yet:

HealthCheckEnabled: Indicates whether health checks are enabled for the target group. It is set to true.

HealthCheckProtocol: References the protocol used for health checks.

HealthCheckIntervalSeconds: References the interval between health checks in seconds.

HealthCheckPath: References the path used for health checks.

HealthCheckPort: References the port used for health checks.

HealthCheckTimeoutSeconds: References the timeout for health checks in seconds.

HealthyThresholdCount: References the number of consecutive successful health checks required to mark a target as healthy.

UnhealthyThresholdCount: References the number of consecutive failed health checks required to mark a target as unhealthy.

Matcher: Defines the HTTP response code used to determine the health of a target.

TargetGroupAttributes: An array property that allows you to define multiple attributes for the target group.

“Key: deregistration_delay.timeout_seconds specifies the attribute key as deregistration_delay.timeout_seconds. This key refers to the attribute that controls the amount of time a target is kept in the "draining" state after it is deregistered from the target group. The "draining" state allows existing connections to complete before the target is completely removed."

With that information, we know that the Value property then sets that value to 0, which will mean the target will immediately be removed from the target group once it's deregistered.

We’re also passing a lot of parameters here, so we add them to our Parameters section of the template.


We’re also passing a lot of parameters here, so we add them to our Parameters section of the template.


```
Parameters:
  CertificateArn:
    Type: String


  # Frontend -----------
  FrontendPort:
    Type: Number
    Default: 3000      
  FrontendHealthCheckIntervalSeconds:
    Type: Number
    Default: 15
  FrontendHealthCheckPath: 
    Type: String
    Default: "/"
  FrontendHealthCheckPort: 
    Type: String
    Default: 80
  FrontendHealthCheckProtocol: 
    Type: String
    Default: HTTP
  FrontendHealthCheckTimeoutSeconds: 
    Type: Number
    Default: 5
  FrontendHealthyThresholdCount: 
    Type: Number
    Default: 2
  FrontendUnhealthyThresholdCount: 
    Type: Number
    Default: 2



  # Backend -----------  
  BackendPort:
    Type: Number
    Default: 4567  
  BackendHealthCheckIntervalSeconds:
    Type: Number
    Default: 15
  BackendHealthCheckPath: 
    Type: String
    Default: "/api/health-check"
  BackendHealthCheckPort: 
    Type: String
    Default: 80
  BackendHealthCheckProtocol: 
    Type: String
    Default: HTTP
  BackendHealthCheckTimeoutSeconds: 
    Type: Number
    Default: 5
  BackendHealthyThresholdCount: 
    Type: Number
    Default: 2
  BackendUnhealthyThresholdCount: 
    Type: Number
    Default: 2
```

You may also note that above for our target groups we haven’t fully implemented the VpcId property. We need to import the value of this from our networking template.yaml via a cross-stack reference. We do this through the use of the Fn::ImportValue function. The Fn::ImportValue function returns the value of an output exported by another stack. In our case, an export from our networking stack. We begin by passing the stack as a parameter.

```
Parameters:
  NetworkingStack:
    Type: String  
    Description: This is our base layer of networking components e.g. VPC, Subnets
    Default: CrdNet
```

We then add the Fn::ImportValue function as the value of our VpcId property.
```
      VpcId: 
        Fn::ImportValue:
          !Sub ${NetworkingStack}VpcId
```

This is added for both the FrontendTG and BackendTG target groups. We're also using the !Sub function to substitute the NetworkingStack variable into the string.

Since we added the parameters to allow cross stack references to our networking layer, we’re now prepared to finish implementing the Subnets property we left blank earlier in our ALB. Andrew notes this is tricky, because they come in as a string, but we're going to need to break them down into an array. To do this, we're going to use the Fn::Split function. This function splits a string into a list of string values, so we can select an element from the resulting string list. Here's a further breakdown of that syntax:   ___Fn::Split: [delimiter, source string]___

```
 ALB:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-loadbalancer.html
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: !Sub "${AWS::StackName}ALB"
      Type: application
      IpAddressType: ipv4
      # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-elasticloadbalancingv2-loadbalancer-loadbalancerattributes.html
      Scheme: internet-facing
      SecurityGroups: 
        - !Ref ALBSG
      Subnets: !Split [",", !ImportValue { "Fn::Sub": "${NetworkingStack}SubnetIds" }]
```

We are using the Fn::Split function (seen in short form here). You can see that our delimiter is a "," , with the source string using the Fn::ImportValue function we used above. Andrew implemented his a bit differently, but I believe I was running into indentation problems, and instead implemented it as one line, as seen above. Andrew's looked like this:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/7b13a351-ec9c-4653-9b27-e6f54f393f70)


In reviewing our template prior to deploying, it’s noted that our original naming for our networking stack was just Cruddur, which will not work for the additional layers we're going to be implementing. We must go back and rename it, setting a naming convention for future layers. We do this by going back to our networking-deploy script.

```
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails
CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/networking/template.yaml"
cfn-lint $CFN_PATH 

aws cloudformation deploy \
    --stack-name "CrdNet" \
    --s3-bucket $CFN_BUCKET \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --tags group="cruddur-networking" \
    --capabilities CAPABILITY_NAMED_IAM
```



Then we update cluster-deploy.
```
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails
CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/networking/template.yaml"
cfn-lint $CFN_PATH 

aws cloudformation deploy \
    --stack-name "CrdCluster" \
    --s3-bucket $CFN_BUCKET \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --tags group="cruddur-cluster" \
    --capabilities CAPABILITY_NAMED_IAM
```

To implement this change, we’re going to have to tear down our existing network stack. We head back over to CloudFormation, and delete the Cruddur stack.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/fda46be0-bb17-4bf4-8d3e-092378f26785)

Andrew mentions we’re also using the Cruddur name for our existing AWS resources as well, which we may run into conflicts about with future CFN templates. To circumvent this, we delete our existing AWS resources including frontend and backend services in ECS, Fargate cluster in ECS, ALB, target groups, Namespace from Cloud Map.

We are now ready to redeploy our network stack. We run networking-deploy, then head over to CloudFormation.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/f3f1d4c2-3b7b-4a90-b270-dd95e75b5fde)

We execute the changeset from CloudFormation, and while we’re waiting come to find that we didn’t update the value imported for our Subnets property of our ALB. To fix this, we have to go back over to our networking template.yaml and make sure of the name of the property being exported for SubnetIds.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/d5142c12-cc45-4d47-8c26-dd338a93a1c1)

It’s just SubnetIds, so we fix this in our cluster template.
```
   Subnets: !Split [",", !ImportValue { "Fn::Sub": "${NetworkingStack}SubnetIds" }]
```



With the stack created successfully, we check our Outputs, and decide we want to add the stack name to our exports. To do this, we use the !Sub function to add a pseudo parameter of the StackName to each output from our networking template.yaml. In the example shown below, we're updating the VpcId property's output:
```
Outputs:
  VpcId:
    Value: !Ref VPC
    Export:
      Name: !Sub "${AWS::StackName}VpcId"
```

We again tear down our networking stack from CloudFormation, then start the cycle all over again: ran networking-deploy script and executed changeset from CFN. Our networking stack re-deploys without any issue, and when we check the Outputs again, they're now updated to include the StackName pseudo parameter.

We’re now ready to test our cluster stack’s deployment. We run cluster-deploy from our terminal. We receive an error from cfn-lint:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/e95ce166-9678-4865-9b43-726109988daa)

We’re receiving an error because our CertificateArn does not have a value. For this, we're wanting to bring in an external value. To do this, we're going to use the library that Andrew created, cfn-toml. This will allow us to pull in external parameters as variables within our deploy scripts, then pass them during creation from our CFN templates. These values are normally hardcoded into the script/command to deploy the CFN template, but with Andrew's library this won't be necessary.

Andrew directs us to his public repo for cfn-toml here: https://github.com/teacherseat/cfn-toml/tree/main and we walk through how to use it. We begin by installing cfn-toml through the CLI:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/c41d0074-3826-43f2-bd75-4849f57473b0)

Then we add this to our .gitpod.yml so it's available to us readily from our workspace whenever we launch it.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/d54f2c4b-8375-43fc-b2cd-e23c2471d078)

From here, we must define that cfn-toml file. In our ./aws/cfn/cluster directory, we create config.toml and config.toml.example to show how to use it.

Here’s config.toml.example:

```
[deploy]
bucket = ''
region = ''
stack_name = ''

[parameters]
CertificateArn = ''

```

This gives us a point of reference for how to define our parameters in config.toml:
```
[deploy]
bucket = 'cfn-artifacts-1'
region = 'us-east-1'
stack_name = 'CrdCluster'

[parameters]
CertificateArn = 'arn:aws:acm:us-east-1:----complete-url-----'
NetworkingStack = 'CrdNet'

```


We now have to update our cluster-deploy script to implement these changes as well:
```
set -e #stop the execution of the script if it fails

CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/cluster/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/cluster/config.toml"

cfn-lint $CFN_PATH 

BUCKET=$(cfn-toml key deploy.bucket -t $CONFIG_PATH)
REGION=$(cfn-toml key deploy.region -t $CONFIG_PATH)
STACK_NAME=$(cfn-toml key deploy.stack_name -t $CONFIG_PATH)
PARAMETERS=$(cfn-toml params v2 -t $CONFIG_PATH)

aws cloudformation deploy \
    --stack-name "CrdCluster" \
    --s3-bucket $BUCKET \
    --region $REGION \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --tags group="cruddur-cluster" \
    --parameter-overrides $PARAMETERS \
    --capabilities CAPABILITY_NAMED_IAM
```



Knowing cfn-toml is working, we decide we want to implement this for our networking stack as well, so we tear this stack down from CloudFormation as well. Then we head back to our workspace and add a config.toml file to our ./aws/cfn/networking directory, filling it in as we go:



```toml
[deploy]
bucket = 'cfn-artifacts-1'
region = 'us-east-1'
stack_name = 'CrdNet'
```


Note, there’s no external parameters we’re needing here, we’re just passing our bucket, region, and stack_name variables for use in the networking-deploy script. Speaking of which, we now update that:


```sh

#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/networking/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/networking/config.toml"

cfn-lint $CFN_PATH

BUCKET=$(cfn-toml key deploy.bucket -t $CONFIG_PATH)
REGION=$(cfn-toml key deploy.region -t $CONFIG_PATH)
STACK_NAME=$(cfn-toml key deploy.stack_name -t $CONFIG_PATH)

aws cloudformation deploy \
    --stack-name $STACK_NAME \
    --s3-bucket $BUCKET \
    --region $REGION \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --tags group="cruddur-networking" \
    --capabilities CAPABILITY_NAMED_IAM
```


You’ll notice since there’s no parameters to pass in the networking config.toml, we remove the PARAMETERS variable completely, along with the command for --parameter-overrides. If we left this, it would give us an error because there's no parameters to pass, as seen below:

We have also updated the CONFIG_PATH variable to the correct path for our networking config.toml file.

We re-deploy, running networking-deploy from the terminal, execute the changeset, and it creates successfully. We try cluster-deploy next. The changeset is created, but when we execute it from CloudFormation, it fails.

We head over to CloudTrail in AWS to check on this error and find that the error occurred during the CreateLoadBalancer event:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/abe87d00-07b5-4307-9240-7cdf094614c4)

We head back over to the cluster template.yaml and view the SecurityGroups property of our ALB. Everything appears correct in the code, so our attention is on the value being passed to SecurityGroups instead.

in security groups, a group ID is used to uniquely identify a security group within a VPC. The group ID is specific to the security group resource and is different from the logical ID assigned by CloudFormation.”

Since we’re needing the Group ID, we must use the Fn::GetAtt function, specifying the GroupId attribute.

We delete the cluster stack from CloudFormation, then go back to our workspace and implement the change suggested by AWS documentation:



```yaml
  SecurityGroups: 
        - !GetAtt ALBSG.GroupId
```



We again deploy our changeset to CloudFormation. A new error is returned.

There’s something wrong with the configuration in our networking layer again. We review the Outputs of our networking stack from CloudFormation:

We’re outputting all of our subnets, both private and public from our networking stack, then importing every single one into the cluster. We don’t need to do this. We only need our private subnets. We decide to go back to the Outputs section of our networking template.yaml and export the private and public subnets separately.


```yaml
  PublicSubnetIds: 
    Value: !Join 
      - "," 
      - - !Ref SubnetPub1 
        - !Ref SubnetPub2 
        - !Ref SubnetPub3
    Export: 
      Name: !Sub "${AWS::StackName}PublicSubnetIds"          
  PrivateSubnetIds: 
    Value: !Join 
      - "," 
      - - !Ref SubnetPriv1
        - !Ref SubnetPriv2
        - !Ref SubnetPriv3
    Export: 
      Name: !Sub "${AWS::StackName}PrivateSubnetIds"
```

We run networking-deploy again, then execute the changeset from CFN. This changeset completes quickly, as it's not changing anything, just adjusting the outputs:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/f54ee7c5-e40b-4c03-ae54-8cbdb4366050)

```yaml
   Subnets: !Split [",", !ImportValue { "Fn::Sub": "${NetworkingStack}PublicSubnetIds" }]
```


We run cluster-deploy, execute the changeset for our cluster layer from CloudFormation, then  error returned.

To fix this, we go back into our cluster template.yaml and view the ALBSG security group we created previously. We're missing a property for VpcId. We add this, importing the value of VpcId from our networking stack.

```yaml
      VpcId: 
        Fn::ImportValue:
          !Sub ${NetworkingStack}VpcId
```

We delete the cluster stack that did not complete successfully in CloudFormation, then run our cluster-deploy script once again. We execute this changeset from CloudFormation, and the stack deploys successfully. You can see the Description we set displayed in the Overview of the stack from CloudFormation.




This should complete the cluster layer, so we’re now able to move onto our service layer. Before proceeding here, Andrew makes mention that he’s deciding how we want to go about this.








# Service Layer

The service layer could include task definitions, but we may want those in a separate CloudFormation template, as they could go through rapid iterations. Just as a general practice, at least from what I’ve studied on this, it can be beneficial to make a separate CFN template for task definitions and the service, as there’s benefits in terms of modularity, reusability, and flexibility. We decide to take a look at our current task definition file for the the backend service. 
We decide to use it as a point of reference and include the task definitions in the same CFN template as the service.

We begin by making a new folder in ./aws/cfn named service, then populate the folder with several new files: config.toml, config.toml.example, and template.yaml. From our ./bin/cfn directory, we create a new script file named service-deploy. Starting off in our service template.yaml, we begin fleshing it out, just the same as our previous CFN templates.


```yaml
AWSTemplateFormatVersion: 2010-09-09
Description: | 
  Task Definition
  Fargate Service
  Execution Role
  Task Role
  
Parameters: 
  NetworkingStack:
    Type: String  
    Description: This is our base layer of networking components e.g. VPC, Subnets
    Default: CrdNet
  ClusterStack:
    Type: String  
    Description: This is our cluster layer e.g. ECS Cluster
    Default: CrdCluster
    
Resources: 
  ServiceSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub ${AWS::StackName}ServSG
      GroupDescription: Security for Fargate Services for Cruddur
      VpcId: !ImportValue
        Fn::Sub: ${NetworkingStack}VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          SourceSecurityGroupId: !GetAtt ALBSG.GroupId
          FromPort: !Ref BackendPort
          ToPort: !Ref BackendPort
          Description: ALB HTTP
```

You can see from above that we already are importing the value of the VpcId and the ALBSecurityGroupId from our networking layer and cluster layer respectively, so we added these stacks as parameters. We're using the networking layer's VpcId, so we must import the value as the the value of VpcId here. Under SecurityGroupIngress, we are defining the inbound rules of the security group, allowing incoming traffic from the cluster layer's security group.

We already know we’re exporting the value of VpcId from our networking template.yaml. Since the cluster stack is referenced as a parameter here and we're importing the value as well, we must set this as an output from our cluster template.yaml and export it:

```yaml
Outputs:  
  ALBSecurityGroupId:
    Value: !GetAtt ALBSG.GroupId
    Export:
      Name: !Sub "${AWS::StackName}ALBSecurityGroupId"
```

We next begin working on the service itself in our template.yaml file. We look up the documentation through AWS, and are immediately hit with this "Important" disclaimer:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/66148e43-12a9-4938-81ac-5cc8746ea72c)

What this message indicates is, in AWS CloudFormation, when you update a stack, any changes to a resource’s properties that require replacement (meaning the resource must be recreated) can result in a failure if there is at least one AWS Service Discovery service (ServiceConnectService) configured for the ECS service. 

> “The reason for this is related to the uniqueness of service names within the AWS Service Discovery namespace. Each AWS Service Discovery service, which provides service discovery capabilities for ECS services, must have a unique name within the namespace. When AWS CloudFormation performs a stack update, it follows a sequence where it creates the replacement service first before deleting the original service.

> However, if there is at least one AWS Service Discovery service associated with the ECS service, the replacement service cannot have the same name as the original service due to the requirement for unique service names. This creates a conflict because AWS CloudFormation tries to create the replacement service with the same name, leading to a stack update failure.”
  
  
  
  
    
  
We continue on, creating our FargateService. There's a lot of properties to define here, so we start out just adding properties we know we're going to need.

```yaml
  FargateService:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ecs-service.html
    Type: AWS::ECS::Service
    Properties: 
      Cluster: 
      DeploymentConfiguration:
      DeploymentController: 
      DesiredCount:
      EnableECSManagedTags: true
      EnableExecuteCommand: true
      HealthCheckGracePeriodSeconds:
      LaunchType: FARGATE
      LoadBalancers: 
        -
      NetworkConfiguration:
      PlatformVersion: LATEST
      PropagateTags: TASK_DEFINITION
      Role:   
      ServiceConnectConfiguration:
      ServiceName:
```


Looking at the already configured service and task definitions files:

```yaml
  FargateService:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ecs-service.html
    Type: AWS::ECS::Service
    Properties: 
      Cluster: 
      DeploymentConfiguration:
      DeploymentController: 
      DesiredCount:
      EnableECSManagedTags: true
      EnableExecuteCommand: true
      HealthCheckGracePeriodSeconds:
      LaunchType: FARGATE
      LoadBalancers:
        - TargetGroupArn:
          ContainerName: backend-flask
          ContainerPort: !Ref ContainerPort
      NetworkConfiguration:
        AwsvpcConfiguration:
          AssignPublicIp: ENABLED
          SecurityGroups:
            - !GetAtt ServiceSG.GroupId
          Subnets: !Split [",", !ImportValue { "Fn::Sub": "${NetworkingStack}PublicSubnetIds" }]
      PlatformVersion: LATEST
      PropagateTags: SERVICE
      ServiceRegistries:
        - RegistryArn: !Sub 'arn:aws:servicediscovery:${AWS::Region}:${AWS::AccountId}:service/srv-cruddur-backend-flask'
          Port: !Ref ContainerPort
          ContainerName: backend-flask
          ContainerPort: !Ref ContainerPort
      ServiceName: !Ref ServiceName
      TaskDefinition: !Ref TaskFamily

```

We add a parameter to the template.yaml file for ContainerPort:

```yaml
Parameters:
  NetworkingStack:
    Type: String  
    Description: This is our base layer of networking components e.g. VPC, Subnets
    Default: CrdNet
  ClusterStack:
    Type: String  
    Description: This is our cluster layer e.g. ECS Cluster
    Default: CrdCluster
  ContainerPort:
    Type: Number
    Default: 4567
    
```

```yaml
  TaskDefinition:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ecs-taskdefinition.html
    Type: AWS::ECS::TaskDefinition
    Properties:
      Family: !Ref TaskFamily
      ExecutionRoleArn: arn:aws:iam::554621479919:role/CruddurServiceExecutionRole
      TaskRoleArn: arn:aws:iam::554621479919:role/CruddurTaskRole
      NetworkMode: awsvpc
      Cpu: !Ref ServiceCpu
      Memory: !Ref ServiceMemory
      RequiresCompatibilities:
        - FARGATE
      ContainerDefinitions:
        - Name: xray
          Image: public.ecr.aws/xray/aws-xray-daemon
          Essential: true
          User: "1337"
          PortMappings:
            - Name: xray
              ContainerPort: 2000
              Protocol: udp
        - Name: backend-flask
          Image: !Ref EcrImage
          Essential: true
          HealthCheck:
            Command:
              - CMD-SHELL
              - python /backend-flask/bin/health-check
            Interval: 30
            Timeout: 5
            Retries: 3
            StartPeriod: 60
          PortMappings:
            - Name: !Ref ContainerName
              ContainerPort: !Ref ContainerPort
              Protocol: tcp
              AppProtocol: http
          LogConfiguration:
            LogDriver: awslogs
            Options:
              awslogs-group: cruddur
              awslogs-region: ${AWS::Region}
              awslogs-stream-prefix: !Ref ServiceName
          Environment:
            - Name: OTEL_SERVICE_NAME
              Value: !Ref EnvOtelServiceName
            - Name: OTEL_EXPORTER_OTLP_ENDPOINT
              Value: !Ref EnvOtelExporterOtlpEndpoint
            - Name: AWS_COGNITO_USER_POOL_ID
              Value: !Ref EnvAWSCognitoUserPoolId
            - Name: AWS_COGNITO_USER_POOL_CLIENT_ID
              Value: !Ref EnvCognitoUserPoolClientId
            - Name: FRONTEND_URL
              Value: !Ref EnvFrontendUrl
            - Name: BACKEND_URL
              Value: !Ref EnvBackendUrl
            - Name: AWS_DEFAULT_REGION
              Value: ${AWS::Region}
          Secrets:
            - Name: AWS_ACCESS_KEY_ID
              ValueFrom: !Ref SecretsAWSAccessKeyId
            - Name: AWS_SECRET_ACCESS_KEY
              ValueFrom: !Ref SecretsSecretAccessKey
            - Name: CONNECTION_URL
              ValueFrom: !Ref SecretsConnectionUrl
            - Name: ROLLBAR_ACCESS_TOKEN
              ValueFrom: !Ref SecretsRollbarAccessToken
            - Name: OTEL_EXPORTER_OTLP_HEADERS
              ValueFrom: !Ref SecretsOtelExporterOtlpHeaders
```


In this code snippet, we’re defining our ECS task definition. We’re specifying the properties and configuration of the task, along with container defintions, networking, resource allocation, logging, environment variables, and secrets. These values and configurations can be setup through click-ops using the AWS console as well.

Lots of parameters added for these values listed here, so we add them in addition to ContainerPort from earlier to our template.yaml.

```yaml
 ServiceCpu:
    Type: String
    Default: '256'
  ServiceMemory:
    Type: String
    Default: '512'
  ServiceName:
    Type: String
    Default: backend-flask
  ContainerName:
    Type: String
    Default: backend-flask
  TaskFamily: 
    Type: String
    Default: backend-flask
  EcrImage:
    Type: String
    Default: '554621479919.dkr.ecr.us-east-1.amazonaws.com/backend-flask'
  EnvOtelServiceName:
    Type: String
    Default: backend-flask
  EnvOtelExporterOtlpEndpoint:
    Type: String
    Default: 'https://api.honeycomb.io'
  EnvAWSCognitoUserPoolId:
    Type: String
    Default: 'us-east-1_N7WWGl3KC'
  EnvCognitoUserPoolClientId:
    Type: String
    Default: '575n8ecqc551iscnosab6e0un3'
  EnvFrontendUrl:
    Type: String
    Default: 'https://thejoshdev.com'
  EnvBackendUrl:
    Type: String
    Default: 'https://api.thejoshdev.com'
  SecretsAWSAccessKeyId:
    Type: String
    Default: 'arn:aws:ssm:us-east-1:999999999999:parameter/cruddur/backend-flask/AWS_ACCESS_KEY_ID' 
  SecretsSecretAccessKey:
    Type: String
    Default: 'arn:aws:ssm:us-east-1:999999999999:parameter/cruddur/backend-flask/AWS_SECRET_ACCESS_KEY'
  SecretsConnectionUrl:
    Type: String
    Default: 'arn:aws:ssm:us-east-1:999999999999:parameter/cruddur/backend-flask/CONNECTION_URL'   
  SecretsRollbarAccessToken:
    Type: String
    Default: 'arn:aws:ssm:us-east-1:999999999999:parameter/cruddur/backend-flask/ROLLBAR_ACCESS_TOKEN'  
  SecretsOtelExporterOtlpHeaders:
    Type: String
    Default: 'arn:aws:ssm:us-east-1:999999999999:parameter/cruddur/backend-flask/OTEL_EXPORTER_OTLP_HEADERS' 
You’ll notice in our TaskDefinition defined in the service template above is hardcoding our values for TaskRoleArn and ExecutionRoleArn currently. That's because we haven't defined IAM roles in our service template yet. We begin by defining our execution policy for our execution role. We navigate to IAM in AWS to view our existing execution policy to reference:

Resources:
  ExecutionPolicy:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: cruddur-execution-policy
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: VisualEditor0
            Effect: Allow
            Action:
              - ecr:GetAuthorizationToken
              - ecr:BatchCheckLayerAvailability
              - ecr:GetDownloadUrlForLayer
              - ecr:BatchGetImage
              - logs:CreateLogStream
              - logs:PutLogEvents
            Resource: "*"
          - Sid: VisualEditor1
            Effect: Allow
            Action:
              - ssm:GetParameters
              - ssm:GetParameter
            Resource: !Sub 'arn:aws:ssm:${AWS::Region}:${AWS::AccountId}:parameter/cruddur/${ServiceName}/*'
```

You’ll notice in our TaskDefinition defined in the service template above is hardcoding our values for TaskRoleArn and ExecutionRoleArn currently. That's because we haven't defined IAM roles in our service template yet. We begin by defining our execution policy for our execution role. We navigate to IAM in AWS to view our existing execution policy to reference:
```yaml
Resources:
  ExecutionPolicy:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: cruddur-execution-policy
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: VisualEditor0
            Effect: Allow
            Action:
              - ecr:GetAuthorizationToken
              - ecr:BatchCheckLayerAvailability
              - ecr:GetDownloadUrlForLayer
              - ecr:BatchGetImage
              - logs:CreateLogStream
              - logs:PutLogEvents
            Resource: "*"
          - Sid: VisualEditor1
            Effect: Allow
            Action:
              - ssm:GetParameters
              - ssm:GetParameter
            Resource: !Sub 'arn:aws:ssm:${AWS::Region}:${AWS::AccountId}:parameter/cruddur/${ServiceName}/*'        
```


In this policy, we’re defining the actions allowed for various AWS resources and services. Here’s what we’re allowing access to:

ecr:GetAuthorizationToken: Allows getting authorization tokens from Amazon Elastic Container Registry (ECR).

ecr:BatchCheckLayerAvailability: Allows batch checking the availability of Docker image layers in ECR.

ecr:GetDownloadUrlForLayer: Allows getting the download URL for a Docker image layer in ECR.

ecr:BatchGetImage: Allows batch getting Docker images from ECR.

logs:CreateLogStream: Allows creating log streams in Amazon CloudWatch Logs.

logs:PutLogEvents: Allows putting log events into Amazon CloudWatch Logs.

ssm:GetParameters: Allows getting parameters from AWS Systems Manager (SSM).

ssm:GetParameter: Allows getting a specific parameter from AWS Systems Manager (SSM).


```yaml
  ExecutionRole:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html
    Type: AWS::IAM::Role
    Properties: 
      RoleName: 'CruddurServiceExecutionRole'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: 'Allow'
            Principal:
              Service: 'ecs-tasks.amazonaws.com'
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - !Sub 'arn:aws:iam::${AWS::AccountId}:policy/${ExecutionPolicy}'
        - 'arn:aws:iam::aws:policy/CloudWatchLogsFullAccess'
```

In the IAM role we defined, we’re allowing the ECS tasks service to assume the role. There’s managed policies attached to grant access to specific permissions required for task execution, including the permissions defined in the referenced ExecutionPolicy parameter we defined above along with CloudWatch Logs access.

We’re now able to reference the role in our TaskDefinition we defined earlier in the service template.yaml.


In the IAM role we defined, we’re allowing the ECS tasks service to assume the role. There’s managed policies attached to grant access to specific permissions required for task execution, including the permissions defined in the referenced ExecutionPolicy parameter we defined above along with CloudWatch Logs access.

We’re now able to reference the role in our TaskDefinition we defined earlier in the service template.yaml.

```yaml
    Type: AWS::ECS::TaskDefinition
    Properties:
      Family: !Ref TaskFamily
      ExecutionRoleArn: !GetAtt ExecutionRole.Arn
      TaskRoleArn: !GetAtt TaskRole.Arn    
```

In the snippet above, we use the !GetAtt function to get the Arn attribute from the ExecutionRole property to define the value of ExecutionRoleArn. Although we haven't defined the TaskRole yet, we add the same for TaskRoleArn.

We should now be able to define our TaskRole. We again go to IAM in AWS to reference the existing task role and begin implementing:

```yaml
  TaskRole:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html
    Type: AWS::IAM::Role
    Properties: 
      RoleName: 'CruddurServiceTaskRole'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:  
          - Effect: 'Allow'
            Principal:
              Service: 'ecs-tasks.amazonaws.com'
            Action: 'sts:AssumeRole' 
      ManagedPolicyArns:
        - !Sub 'arn:aws:iam::${AWS::AccountId}:policy/${TaskPolicy}'
        - 'arn:aws:iam::aws:policy/CloudWatchLogsFullAccess'
        - 'arn:aws:iam::aws:policy/AWSXRayDaemonWriteAccess'
        
```

Very much like our ExecutionRole property above, we're allowing the ECS tasks service to assume the role. We're attached managed policies to grant specific permissions for tasks. This time, we're giving permissions for SSM messages, CloudWatch Logs access, and AWS X-Ray Daemon write access.

Then we add the TaskPolicy to define the SSM message permissions:

```yaml
  TaskPolicy:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: cruddur-task-policy
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: VisualEditor0
            Effect: Allow
            Action:
              - ssmmessages:CreateControlChannel
              - ssmmessages:CreateDataChannel
              - ssmmessages:OpenControlChannel
              - ssmmessages:OpenDataChannel
            Resource: "*"
```

Our service template.yaml looks to be good for now, so we move our attention to our service-deploy script. We begin by copying our existing cluster-deploy script and then editing it specific for the service layer instead:

```bash
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/service/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/service/config.toml"

cfn-lint $CFN_PATH 

BUCKET=$(cfn-toml key deploy.bucket -t $CONFIG_PATH)
REGION=$(cfn-toml key deploy.region -t $CONFIG_PATH)
STACK_NAME=$(cfn-toml key deploy.stack_name -t $CONFIG_PATH)
PARAMETERS=$(cfn-toml params v2 -t $CONFIG_PATH)

aws cloudformation deploy \
    --stack-name $STACK_NAME \
    --s3-bucket $BUCKET \
    --region $REGION \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --tags group="cruddur-backend-flask" \
    --parameter-overrides $PARAMETERS \    
    --capabilities CAPABILITY_NAMED_IAM
    
```



We have adjusted the pathing for our CFN_PATH and CONFIG_PATH variables to reflect the service layer pathings. We also implement our config.toml file for the service layer as well:
```toml
[deploy]
bucket = 'cfn-artifacts-1'
region = 'us-east-1'
stack_name = 'CrdSrvBackendFlask'
```

After running our chmod u+x ./bin/cfn/service-deploy to make our script executable, we run the service-deploy script. We begin working through a myriad of errors and warnings from cfn-lint. First, we realize we didn't define a value for the Cluster property of the FargateService. We import the value from our cluster stack.

```yaml
  FargateService:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ecs-service.html
    Type: AWS::ECS::Service
    Properties: 
      Cluster: 
        Fn::ImportValue:
          !Sub "${ClusterStack}ClusterName"
```

Since we imported the value of the cluster name from our cluster stack, we have to go back to our cluster template.yaml to export it as well.

```yaml
Outputs:
  ClusterName:
    Value: !Ref FargateCluster
    Export:
      Name: !Sub "${AWS::StackName}ClusterName"
```

With this change, before our service layer can be deployed, we have to redeploy the cluster layer for that Output. We run our cluster-deploy script again, then execute the changeset created from CloudFormation. When it completes, we have a status of UPDATE_COMPLETE, so we check out Outputs to make sure.

We now have the ClusterName as an Output.

We continue working through the errors for our service template.yaml:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/6f11729a-a813-4584-b566-0b725372756b)


We remove the CidrIp property from our ServiceSG as we no longer need it since we defined the value of SourceSecurityGroupId by importing the value from out cluster layer's ALB security group.

```
Resources:
  ServiceSG:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-security-group.html
    Type: AWS::EC2::SecurityGroup
    Properties: 
      GroupName: !Sub "${AWS::StackName}AlbSG"
      GroupDescription: Public Facing SG for our Cruddur ALB
      VpcId: 
        Fn::ImportValue:
          !Sub ${NetworkingStack}VpcId 
      SecurityGroupIngress:
        - IpProtocol: tcp
          SourceSecurityGroupId:
            Fn::ImportValue:
              !Sub ${ClusterStack}ALBSecurityGroupId       
          FromPort: 80
          ToPort: 80
          Description: ALB HTTP
```


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/a00d3736-b992-4659-a4c7-762df5a5b03a)

There’s also several missing values for properties of our FargateService that we need to define as well. We're not going to use DeploymentConfiguration, so we remove the property entirely. We then define values for DeploymentController and DesiredCount.

```
      DeploymentController: 
        Type: ECS
      DesiredCount: 1

```

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/1e4c1649-b2c0-4b3e-a72c-6fae773397c2)

We update the HealthCheckGracePeriodSeconds property of the FargateService to 0.
![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/14f0f915-5f67-4185-a837-c7c1a04a6533)

Our TaskDefinition is using embedded parameters outside of a function. We edit this to correct it for awslogs-region and the value of an env var defined under Environment.


```yaml
              awslogs-region: !Ref AWS::Region
            - Name: AWS_DEFAULT_REGION
              Value: !Ref AWS::Region

```

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/fb25ba21-673b-47eb-83e3-beca261732e6)

To fix these errors, we decide to alter our existing policies to be inline with our roles. First the task role:


```yaml
  TaskRole:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html
    Type: AWS::IAM::Role
    Properties: 
      RoleName: 'CruddurServiceTaskRole'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: 'Allow'
            Principal:
              Service: 'ecs-tasks.amazonaws.com'
            Action: 'sts:AssumeRole'
      Policies:
        - PolicyName: 'cruddur-task-policy'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Sid: VisualEditor0
                Effect: Allow
                Action:
                  - ssmmessages:CreateControlChannel
                  - ssmmessages:CreateDataChannel
                  - ssmmessages:OpenControlChannel
                  - ssmmessages:OpenDataChannel
                Resource: "*"              
      ManagedPolicyArns:
        - !Sub 'arn:aws:iam::${AWS::AccountId}:policy/${TaskPolicy}'
        - 'arn:aws:iam::aws:policy/CloudWatchLogsFullAccess'
        - 'arn:aws:iam::aws:policy/AWSXRayDaemonWriteAccess'
```


Then, the execution role:
```


  ExecutionRole:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html
    Type: AWS::IAM::Role
    Properties: 
      RoleName: 'CruddurServiceExecutionRole'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: 'Allow'
            Principal:
              Service: 'ecs-tasks.amazonaws.com'
            Action: 'sts:AssumeRole'
      Policies:
        - PolicyName: 'cruddur-execution-policy'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Sid: VisualEditor0
                Effect: Allow
                Action:
                  - ecr:GetAuthorizationToken
                  - ecr:BatchCheckLayerAvailability
                  - ecr:GetDownloadUrlForLayer
                  - ecr:BatchGetImage
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "*"
              - Sid: VisualEditor1
                Effect: Allow
                Action:
                  - ssm:GetParameters
                  - ssm:GetParameter
                Resource: !Sub 'arn:aws:ssm:${AWS::Region}:${AWS::AccountId}:parameter/cruddur/${ServiceName}/*'            
      ManagedPolicyArns:
        - !Sub 'arn:aws:iam::${AWS::AccountId}:policy/${ExecutionPolicy}'
        - 'arn:aws:iam::aws:policy/CloudWatchLogsFullAccess'
```
![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/1038f9e2-2150-4bad-b206-4f5623c60dd9)


This error is coming from cfn-toml. We're not passing any parameters in our config.toml file, so we comment out the PARAMETERS variable pathing, and the command from the service-deploy script as well:

```bash
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/service/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/service/config.toml"

cfn-lint $CFN_PATH 

BUCKET=$(cfn-toml key deploy.bucket -t $CONFIG_PATH)
REGION=$(cfn-toml key deploy.region -t $CONFIG_PATH)
STACK_NAME=$(cfn-toml key deploy.stack_name -t $CONFIG_PATH)
#PARAMETERS=$(cfn-toml params v2 -t $CONFIG_PATH)

aws cloudformation deploy \
    --stack-name $STACK_NAME \
    --s3-bucket $BUCKET \
    --region $REGION \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --tags group="cruddur-backend-flask" \
    --capabilities CAPABILITY_NAMED_IAM
    #--parameter-overrides $PARAMETERS \
```


With this error fixed, we again run service-deploy. This time, a changeset is created, so we head over to CloudFormation and execute it. When we check the Events tab of CloudFormation, we have a status of CREATE_FAILED.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/767de406-d793-4d1f-b4c0-f378ba4f2e19)

We knew this would happen, as the IAM role we’re trying to create already exists with that same name. We delete the stack from CFN, then head over to IAM and delete the existing CruddurServiceExecutionRole and CruddurTaskRole.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/860a462e-f4f1-41d1-ae86-d0578a4fa288)

We run service-deploy again, then execute the changeset once more. This time, our create fails again, but for a different reason:

For our task role:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/c6fe025e-9e7c-4698-a4ae-06b90aaabe87)

For our execution role:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/38f4423e-6ec8-41c2-b7ef-68bd1b2f2a6e)

We move back to CloudFormation, delete the service stack since it hasn’t successfully deployed yet, then run our service-deploy script once more. We then execute the changeset from CloudFormation again:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/24f9a95e-b45e-4a43-88a6-3d85f9437ac5)

This is likely due to the value of the TargetGroupArn property of our LoadBalancer under FargateService is still a hard-coded value pulled from our existing task definition file earlier. We head back to our workspace and find this to be the case.

To fix the issue, we open our cluster template.yaml and add a couple of Outputs, as we're going to need target group ARN's for both our frontend and backend services.

```yaml
 FrontendTGArn:
    Value: !Ref FrontendTG
    Export: 
      Name: !Sub "${AWS::StackName}FrontendTGArn"
  BackendTGArn:
    Value: !Ref BackendTG
    Export: 
      Name: !Sub "${AWS::StackName}BackendTGArn"
```


Just so these outputs are available to us for our service layer, we must run cluster-deploy again and execute the changeset from CloudFormation. Since there's no infrastructure changes, the changeset completes successfully almost instantly. When we check our Outputs, we now have a FrontendTGArn and BackendTGArn listed for our cluster layer.

Now we can cross stack reference these Outputs in our service template.yaml. We fix the TargetGroupArn property for our FargateService load balancer.

Just so these outputs are available to us for our service layer, we must run cluster-deploy again and execute the changeset from CloudFormation. Since there's no infrastructure changes, the changeset completes successfully almost instantly. When we check our Outputs, we now have a FrontendTGArn and BackendTGArn listed for our cluster layer.

Now we can cross stack reference these Outputs in our service template.yaml. We fix the TargetGroupArn property for our FargateService load balancer.

```yaml
   LoadBalancers:
        - TargetGroupArn:
            Fn::ImportValue:
              !Sub "${ClusterStack}BackendTGArn"  
```

With these changes, we delete the service stack from CFN as it never successfully deployed, then run our service-deploy script again. In CloudFormation, we execute the changeset:

We go ahead and tear down the stack since it didn’t deploy, then head back over to our workspace and view our cluster template.yaml, specifically looking for our target group for the backend service. We're missing the TargetType property for our target groups. We consult the AWS documentation on this:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/15e9890b-68b0-4d55-8313-32dc8880f52e)

Since this value wasn’t being set by us, for an application load balancer target group such as this, the default value of TargetType was set to instance, meaning the target group would target EC2 instances instead of our Fargate Service. We add this property for both the frontend and backend target groups, specifying ip as the value instead.

```
  TargetType: ip
```

We again want to update our cluster layer, so we again run the cluster-deploy script, execute the changeset from CFN and wait for the results:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/d90cc68e-c930-4929-acbf-a49a9f292dc9)

We’re getting errors that the target groups already exist and won’t update. After a bit of research we find this is likely due to the name of the target group being defined. Since we provided the name in the template, CFN is erroring when trying to update because the name already exists. CloudFormation associates the logical ID with the resource. If the logical ID remains unchanged, CFN should recognize the resource is already created and update it. Since the name is defined already, AWS is basically telling us there’s nothing to update.

```
   #Name: !Sub "${AWS::StackName}FrontendTG"
```

```
#Name: !Sub "${AWS::StackName}BackendTG"
```


Instead, we decide to implement tags.
```
      Tags: 
        - Key: target-group-name
          Value: frontend  
      Tags: 
        - Key: target-group-name
          Value: backend
```

We again run the cluster-deploy script and execute the changeset from CloudFormation. The cluster stack shows UPDATE_COMPLETE status. Just to see the changes, we head over to EC2 in AWS to view our target groups and how they're now named:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/1d3f2b36-99ff-487f-8308-e1e4001f7110)

When we select the backend target group, we’re able to see our tags are applied successfully:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/d7277885-4901-441d-94d9-0005e631c5cc)

We head back over to our workspace and attempt to deploy our service stack via the service-deploy script. Then we execute the changeset from CloudFormation again. We have another CREATE_FAILED status:
![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/18fc2aac-7e32-4043-be09-8a5788dd7c4e)

We open CloudTrail through AWS, and take a look at the CreateService action, as it's the last action that ran prior to the rollback.


Andrew believes the issue is with the Service Connect for the backend service. We go back to our workspace and open our ./aws/json/service-backend-flask.json file to view the existing configuration:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/dcacc279-8be9-4998-bfe0-a5a41b84d97b)

Andrew believes the issue is with the Service Connect for the backend service. We go back to our workspace and open our ./aws/json/service-backend-flask.json file to view the existing configuration:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/2b9ac135-428e-4935-81a4-50b168a8b842)

We compare this to the service template.yaml and how it was implemented. Our existing code makes use of the ServiceRegistries property for the FargateService. It has a RegistryArn property defined, so that would mean the service already exists, which it shouldn't. We're not even using the ServiceConnectConfiguration property. We comment out our ServiceRegistries property and instead define ServiceConnectConfiguration:

```yaml
    ServiceConnectConfiguration:
          Enabled: true
          Namespace: "cruddur"
          # TODO - If you want to log
          # LogConfiguration:
          Services: 
            - DiscoveryName: "backend-flask"
              PortName: "backend-flask"
              ClientAliases:
                - Port: 4567

      #ServiceRegistries:
      #  - RegistryArn: !Sub 'arn:aws:servicediscovery:${AWS::Region}:${AWS::AccountId}:service/srv-cruddur-backend-flask'
      #    Port: !Ref ContainerPort
      #    ContainerName: backend-flask
      #    ContainerPort: !Ref ContainerPort
```


We again delete the existing service stack from CloudFormation, then run service-deploy and execute the changeset. After an extended period of time, we refresh the Events tab of CloudFormation, but the FargateService is still being created by CloudFormation. We decide to head over to ECS in AWS instead to check the service. We can see already there's tasks failing. We click into one to see what's going on:




 ![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/1d343142-cd56-4fe3-8ca0-5a9765d9ef70)

Andrew believes this could be due to an issue with the health check on the container is so fast that it does not detect when the app fails and/or issues with the ports for the security group. We head over to the security group for the backend service in EC2 and edit the Inbound Rules, opening up the ports for all traffic, just for testing purposes. Our tasks are still failing at this point. We decide to adjust our health check settings for the target group in EC2. We head over there, and select the Health Check tab for our backend target group then edit it manually through the console:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/629122ed-02af-40e3-9252-406e917499a2)

Tasks are still failing. We attempt to run the backend service from our ./bin/backend/deploy script updating the values to our existing layer information, but this fails. We update the HealthCheckGracePeriodSeconds property of our FargateService in the service template to 100 seconds, redeploy the service stack, and this makes no change. Our tasks are still failing.

We’re going to redeploy the service layer again, but prior to this, we are going to make sure to give access to the service security group for our database. We again access our service template.yaml and add an Output for the security group:

```
Outputs: 
  ServiceSecurityGroupId:
    Value: !GetAtt ServiceSG.GroupId
    Export:
      Name: !Sub "${AWS::StackName}ServiceSecurityGroupId"
```

After many troubleshooting attempts, we find that the tasks are failing because of our existing PostGres database. The health check of the tasks are probably failing because the tasks are starting up while there’s connection issues to the database as the service starts. The connection issue is because the database has no access to the service security group. Since we haven’t setup our new database yet, this is going to continue to fail.

We’re going to have to leave the service layer in an uncompleted state for now, and move onto the RDS layer, then we can circle back and complete the service layer at that time. We go ahead and delete the service layer stack from CloudFormation.

## Database (RDS) Layer
We begin the RDS layer by creating a new folder in the ./aws/cfn directory named db. We create a new template.yaml in this folder as well. We begin as always, fleshing out the RDS template.


```yaml
AWSTemplateFormatVersion: 2010-09-09
Description: |
  The primary Postgres RDS Database for the application
  - RDS Instance
  - Database Security Group
  - DBSubnetGroup
  
  Parameters:
  Resources:
#Outputs: 
#  ServiceSecurityGroupId:
#    Value: !GetAtt ServiceSG.GroupId
#    Export:
#      Name: !Sub "${AWS::StackName}ServiceSecurityGroupId"
```

 Andrew notes that we want the security group from our service layer, but just in case we end up not needing it, we will comment it out for now. Next we bring in our RDS instance:
 
```yaml
 Resources:
  # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-rds-dbinstance.html
  Type: AWS::RDS::DBInstance
  # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html
  DeletionPolicy: 'Snapshot'
  # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-updatereplacepolicy.html
  UpdateReplacePolicy: 'Snapshot'
  Properties: 
    AllocatedStorage: '20'
    AllowMajorVersionUpgrade: true
    AllowMinorVersionUpgrade: true
    BackupRetentionPeriod: !Ref BackupRetentionPeriod
    DBInstanceClass: !Ref DBInstanceClass
```


You might notice some particular properties of the Resources. Let's break those down a bit here:

DeletionPolicy: Specifies the deletion policy for the resource, which is set to 'Snapshot'. This means that when the resource is deleted, a final snapshot will be created before deletion.

UpdateReplacePolicy: Specifies the update/replace policy for the resource, which is set to 'Snapshot'. This means that when the resource is updated, it will be replaced with a new resource and a snapshot of the old resource will be created.

Let’s break down the rest of the properties:

AllocatedStorage: This property specifies the amount of storage allocated for the RDS database instance. In this case, it is set to '20', indicating 20 gigabytes of storage. This keeps us in the free tier of AWS.

AllowMajorVersionUpgrade: This property determines whether major version upgrades are allowed for the database engine. When set to true, it allows the RDS instance to be upgraded to a new major version when available.

AllowMinorVersionUpgrade: This property determines whether minor version upgrades are allowed for the database engine. When set to true, it allows the RDS instance to be upgraded to a new minor version when available.

BackupRetentionPeriod: This property specifies the number of days to retain automated backups of the database.

DBInstanceClass: This property specifies the instance class for the RDS database instance.

You may have noticed we referenced parameters for the BackupRetentionPeriod and DBInstanceClass properties. We add these parameters as well:

```
Parameters:
  BackupRetentionPeriod:
    Type: Number
    Default: 0
  DBInstanceClass: 
    Type: String
    Default: db.t4g.micro
```

The BackupRetentionPeriod default value of 0 is not optimal for production environments, as you may want to retain automated backups of your database for data recovery, compliance and regulation requirements, operational best practices, or testing and developement purposes. We are simply setting it this way to remain in the free tier of AWS.

We also have set the InstanceClass parameter that we reference for the InstanceClass property to db.t4g.micro, which, according to AWS documentation is "designed for workloads with lower resource requirements and intermittent usage patterns. It can be a cost-effective choice for smaller applications or development/testing environments where consistent high CPU performance is not required."

We continue on, adding and adjusting properties to our RDS template.yaml .

```
  Database:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-rds-dbinstance.html
    Type: AWS::RDS::DBInstance
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html
    DeletionPolicy: 'Snapshot'
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-updatereplacepolicy.html
    UpdateReplacePolicy: 'Snapshot'
    Properties: 
      AllocatedStorage: '20'
      AllowMajorVersionUpgrade: true
      AutoMinorVersionUpgrade: true
      BackupRetentionPeriod: !Ref BackupRetentionPeriod
      DBInstanceClass: !Ref DBInstanceClass
      DBInstanceIdentifier: !Ref DBInstanceIdentifier
      DBName: !Ref DBName
      DBSubnetGroupName: !Ref DBSubnetGroup
```

We’ve added a few properties to the DBInstance, and we've also given it a reference of Database. Here's a bit more on the added properties:

DBInstanceIdentifier: This property specifies the identifier for the Amazon RDS database instance. The identifier is a user-defined name that identifies the RDS instance within our AWS account.

DBName: This property specifies the name of the initial database that will be created in the Amazon RDS instance. When the RDS instance is provisioned, this database will be created and available for use.

DBSubnetGroupName: This property specifies the name of the DB subnet group associated with the RDS instance. A DB subnet group is a collection of subnets in our VPC where RDS instances can be created. The subnet group defines the network configuration for the RDS instance, including the availability zones and subnets where the instance will be placed.

We also add parameters for these properties:

```yaml
  DBInstanceIdentifier: 
    Type: String
    Default: cruddur-instance
  DBName: 
    Type: String
    Default: cruddur
```


As for DBSubnetGroup, it's an AWS resource we must define, so we start on it in our RDS template.yaml.

```
DBSubnetGroup:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-rds-dbsubnetgroup.html
    Type: AWS::RDS::DBSubnetGroup
    Properties:
```

We move back to our RDS instance and continue on, defining more properties:
```yaml
 Database:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-rds-dbinstance.html
    Type: AWS::RDS::DBInstance
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html
    DeletionPolicy: 'Snapshot'
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-updatereplacepolicy.html
    UpdateReplacePolicy: 'Snapshot'
    Properties: 
      AllocatedStorage: '20'
      AllowMajorVersionUpgrade: true
      AutoMinorVersionUpgrade: true
      BackupRetentionPeriod: !Ref BackupRetentionPeriod
      DBInstanceClass: !Ref DBInstanceClass
      DBInstanceIdentifier: !Ref DBInstanceIdentifier
      DBName: !Ref DBName
      DBSubnetGroupName: !Ref DBSubnetGroup
      DeletionProtection: !Ref DeletionProtection
      EnablePerformanceInsights: true
      Engine: postgres
      EngineVersion: !Ref EngineVersion

# Must be 1 to 63 letters or numbers.
# First character must be a letter.
# Can't be a reserved word for the chosen database engine.
      MasterUsername:  !Ref MasterUsername
      # Constraints: Must contain from 8 to 128 characters.
      MasterUserPassword: !Ref MasterUserPassword
      PubliclyAccessible: true
      VPCSecurityGroups:
        - !GetAtt RDSPostgresSG.GroupId
```

More on the new properties we added:

DeletionProtection: This property enables deletion protection for the RDS instance. When deletion protection is enabled, it prevents accidental deletion of the RDS instance.

EnablePerformanceInsights: This property enables Performance Insights for the RDS instance. Performance Insights is a feature that helps you monitor the performance of your RDS database.

Engine: This property specifies the database engine to be used for the RDS instance. In our case, it is set to postgres, indicating that PostgreSQL will be used as the database engine.

EngineVersion: This property specifies the version of the database engine to be used.

MasterUsername: This property specifies the username for the master user of the RDS instance. The master user has administrative privileges and is used to manage the database.

MasterUserPassword: This property specifies the password for the master user of the RDS instance. As we commented in the code, the MasterUserPassword must contain from 8 to 128 characters.

PubliclyAccessible: This property determines whether the RDS instance can be accessed publicly over the internet. Setting it to true allows public access, while setting it to false restricts access to within the VPC.

VPCSecurityGroups: This property specifies the VPC security groups associated with the RDS instance.

We also add additional parameters for the properties that reference them, but we’ll come back to MasterUsername and MasterUserPassword:



```yaml
 DeletionProtection:
    Type: String
    AllowedValues:
      - true
      - false
    Default: true
  EngineVersion: 
    Type: String
    #  DB Proxy only supports very specific versions of Postgres
    #  https://stackoverflow.com/questions/63084648/which-rds-db-instances-are-supported-for-db-proxy
    Default: '15.2'
```

We move back to the DBSubnetGroup we started and continue on adding properties for that resource:

```yaml

 DBSubnetGroup:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-rds-dbsubnetgroup.html
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupName: !Sub "${AWS::StackName}DBSubnetGroup"
      DBSubnetGroupDescription: !Sub "${AWS::StackName}DBSubnetGroup"
      SubnetIds: { 'Fn::Split' : [ ','  , { "Fn::ImportValue": { "Fn::Sub": "${NetworkingStack}PublicSubnetIds" }}] }
 ```

DBSubnetGroupName: we're defining the name of our DB subnet group. It's going to substitute the property value with the stack name followed by "DBSubnetGroup"

DBSubnetGroupDescription: we are defining the description of the DB subnet group here. It's value is the same as DBSubnetGroupName

SubnetIds: we're defining the list of subnet IDs that will be associated with the DB subnet group. We're importing the value from the network layer for the PublicSubnetIds property. Using the Fn::Split function, we're splitting the retrieved subnet IDs from PublicSubnetIds and creating a list.

To use the PublicSubnetIds property for SubnetIds, we add the network layer as a parameter, as we did previously in our cluster layer.

```yaml
Parameters:
  NetworkingStack:
    Type: String  
    Description: This is our base layer of networking components e.g. VPC, Subnets
    Default: CrdNet
```

We now move onto our RDSPostgresSG security group and continue working on that in our RDS template.yaml:

```yaml
  RDSPostgresSG:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-security-group.html
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub "${AWS::StackName}RDSSG"
      GroupDescription: Public Facing SG for our Cruddur ALB
      VpcId:
        Fn::ImportValue:
          !Sub ${NetworkingStack}VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          SourceSecurityGroupId:
            Fn::ImportValue:
              !Sub ${ClusterStack}ServiceSecurityGroupId
          FromPort: 5432
          ToPort: 5432
          Description: ALB HTTP
```

No need to break down these properties, we’ve already seen a security group. You might notice however that SourceSecurityGroupId property is importing the value of ServiceSecurityGroupId from the cluster stack. We have not yet created this yet.

Andrew explains: “When we launch our service, its supposed to have access to this(Postgres security group) so we’re supposed to add it here. The problem is we’ve yet to create our service, but we’re setting this up right now. We need to have already in place, the service security group.”

This should resolve the issue we were running into with our service layer being deployed to CloudFormation. We go ahead and move back to our cluster template.yaml and add the security group:

```
# We have to create this SG before the service so we can pass it to database SG
  ServiceSG:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-security-group.html
    Type: AWS::EC2::SecurityGroup
    Properties: 
      GroupName: !Sub "${AWS::StackName}ServSG"
      GroupDescription: Security for Fargate Services for Cruddur
      VpcId: 
        Fn::ImportValue:
          !Sub ${NetworkingStack}VpcId 
      SecurityGroupIngress:
        - IpProtocol: tcp
          SourceSecurityGroupId: !GetAtt ALBSG.GroupId
          FromPort: 80
          ToPort: 80
          Description: ALB HTTP
```

We’re adding access to our existing ALBSG through use of the SourceSecurityGroupId property value. Since it's within the same stack, we're using !GetAtt to retrieve the attribute GroupId from ALBSG. We also access the ServiceSG from our service template.yaml and completely remove it, as it's now being defined in our RDS layer instead. Since we're still going to need to define the security group in our service layer, we need to export ServiceSG from our cluster template.yaml.


```
 ServiceSecurityGroupId:
    Value: !GetAtt ServiceSG.GroupId
    Export:
      Name: !Sub "${AWS::StackName}ServiceSecurityGroupId"
```

Since we’re going to import this value in our RDS layer, we must add the ClusterStack to our parameters in the RDS template.yaml:

```
  ClusterStack:
    Type: String
    Description: This is our FargateCluster
    Default: CrdCluster
```

We move back over to our RDS template.yaml again and come back to the MasterUsername and MasterUserPassword properties of our Database. We use the !Ref function to pass values for both properties using parameters. We name the parameters according to the property name, then define the parameters:

```
  MasterUsername:
    Type: String
  MasterUserPassword:
    Type: String
    NoEcho: true
```

We’re using the NoEcho parameter property for the MasterUserPassword after consulting AWS documentation for this. According to AWS, "Whether to mask the parameter value to prevent it from being displayed in the console, command line tools, or API. If you set the NoEcho attribute to true, CloudFormation returns the parameter value masked as asterisks for any calls that describe the stack or stack events,".

With that, we have defined parameters not explicitly set in the Parameters field of the RDS template. For these, we create another config.toml file, in our ./aws/cfn/db directory and implement it:

```yaml
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/db/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/db/config.toml"

cfn-lint $CFN_PATH 

BUCKET=$(cfn-toml key deploy.bucket -t $CONFIG_PATH)
REGION=$(cfn-toml key deploy.region -t $CONFIG_PATH)
STACK_NAME=$(cfn-toml key deploy.stack_name -t $CONFIG_PATH)
PARAMETERS=$(cfn-toml params v2 -t $CONFIG_PATH)

aws cloudformation deploy \
    --stack-name $STACK_NAME \
    --s3-bucket $BUCKET \
    --region $REGION \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --tags group="cruddur-db" \
    --parameter-overrides $PARAMETERS MasterUserPassword=$DB_PASSWORD \
    --capabilities CAPABILITY_NAMED_IAM
```

The script is very much like our other scripts. We’ve updated CFN_PATH and CONFIG_PATH to the pathing for our RDS template and RDS config.toml file respectively. You will also notice that we're overriding the parameter for MasterUserPassword with the value of the env var $DB_PASSWORD by way of the --parameter-overrides command.

From there, we now need to set the $DB_PASSWORD env var from our terminal. I'll redact my Postgres database password and instead use "example" for reference point here:

The script is very much like our other scripts. We’ve updated CFN_PATH and CONFIG_PATH to the pathing for our RDS template and RDS config.toml file respectively. You will also notice that we're overriding the parameter for MasterUserPassword with the value of the env var $DB_PASSWORD by way of the --parameter-overrides command.

From there, we now need to set the $DB_PASSWORD env var from our terminal. I'll redact my Postgres database password and instead use "example" for reference point here:

```yaml
export DB_PASSWORD=example
gp env DB_PASSWORD=example
```

Our RDS layer looks to be nearing completion. With that, the Outputs parameters we have added to our cluster template.yaml will need to be available to us before we can deploy the RDS layer. So we redeploy the cluster layer, running cluster-deploy. Then we execute the changeset created from CloudFormation.

The cluster layer updates successfully. We make the RDS script executable by chmod’ing the file: chmod u+x ./bin/cfn/db-deploy, then we run the script. Andrew receives an error from cfn-lint, as he's implemented the DBSubnetGroup resource property SubnetIds using multiple lines.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/b50a7d17-4ac4-4a12-8981-2f8c3868efff)

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/11d1912c-b751-4740-a986-b8cd1bb78a9b)

My changeset is created successfully however, due to implementing the SubnetIds in one line:

```json
SubnetIds: { 'Fn::Split' : [ ','  , { "Fn::ImportValue": { "Fn::Sub": "${NetworkingStack}PublicSubnetIds" }}] }
```

Andrew adjusts his SubnetIds to the same as mine, and informs us that this is the exact example he's been telling us about where sometimes certain functions will not work inside of other ones. In these cases, you have to use the .json equivalent of the function instead of the .yaml version. (i.e. Fn::Sub instead of !Sub )

We execute the changeset from CloudFormation.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/9c434c85-d1dc-422c-8b9f-369d1ea9ac85)

Our database has been created successfully. We select the cruddur-instance resource from CloudFormation which redirects us to RDS in AWS.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/de1d8d72-00a3-4f39-8469-9763c76bfbd6)

You can see that we now have our original database, cruddur-db-instance and our new database, cruddur-instance. There's no data in our new one yet, Andrew mentions we COULD load a snapshot to prefill our data, but instead we're likely going to reseed it at a later time. Andrew also lets us know that the CONNECTION_URL to our database is going to be a bit different as well, so we navigate over to AWS System Manager, then Parameter Store to update this parameter.


Service Layer: First Blood Part II
We begin by going back to our service template.yaml, as we need to reference the security group we created in our cluster layer. We're already referencing the ClusterStack as a parameter, so we import the value of the ServiceSecurityGroupId for the SecurityGroups property of the FargateService resource.


```yaml
    SecurityGroups:
            - Fn::ImportValue:
                !Sub "${ClusterStack}ServiceSecurityGroupId"
```







![Screenshot 2024-03-23 151014](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/39278b5c-4b48-4b0a-b18e-0e778ffc49f8)
![Screenshot 2024-03-23 150524](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/a8b26aed-771a-4049-a638-b251884c7f55)
![Screenshot 2024-03-23 150628](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/231bf294-04c3-4e60-a711-372634d07e8d)




























## DynamoDB Layer (SAM)


A little bit on SAM. SAM, or Serverless Application Model CloudFormation templates are an extension of CloudFormation templates. They’re specifically designed for building serverless applications. I asked “Here are some key features and benefits of SAM CFN templates:

Simplified Syntax: SAM templates provide a simplified syntax that reduces the amount of code needed to define serverless resources compared to traditional CloudFormation templates. This makes it easier to author and read templates for serverless applications.

Serverless Resources: SAM introduces new resource types and properties that are optimized for serverless applications, such as AWS Lambda functions, Amazon API Gateway APIs, Amazon DynamoDB tables, and AWS Step Functions state machines. These resources can be defined in a more concise and expressive manner in SAM templates.

Built-in Transform: SAM templates use a built-in CloudFormation transform called AWS::Serverless-2016–10–31. This transform automatically converts SAM-specific resources and properties into their equivalent CloudFormation resources during deployment. It allows you to use SAM features without sacrificing the flexibility and power of CloudFormation.

Local Development and Testing: SAM provides a local development and testing experience through the AWS SAM CLI (Command Line Interface). With the SAM CLI, you can invoke and debug Lambda functions locally, emulate AWS service integrations, and package and deploy your application to AWS. SAM templates work seamlessly with the SAM CLI, enabling efficient local development and testing workflows.

Predefined Event Sources: SAM templates offer predefined event sources that simplify the configuration of event-driven architectures. For example, you can define an Amazon S3 bucket as an event source for a Lambda function directly in the template, without the need for additional configuration.

Resource Policies: SAM templates support resource policies that allow you to define fine-grained access control for your serverless resources. Resource policies enable you to set permissions at the resource level, defining who can invoke your Lambda functions or access your API Gateway APIs.

Overall, SAM CFN templates provide a higher-level abstraction and convenience for building serverless applications on AWS. They make it easier to define and deploy serverless resources and integrate them with other AWS services.”


We start off the DynamoDb layer by creating a new folder named ddb within our ./aws/cfn directory. Then we create our template.yaml and config.toml files in the folder. We then head over to ./bin/cfn and create ddb-deploy as our script to deploy the DDB layer. We start off with the ddb-deploy script, copying the contents of the db-deploy script and editing it as we go:

```py
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/config.toml"

cfn-lint $CFN_PATH 

BUCKET=$(cfn-toml key deploy.bucket -t $CONFIG_PATH)
REGION=$(cfn-toml key deploy.region -t $CONFIG_PATH)
STACK_NAME=$(cfn-toml key deploy.stack_name -t $CONFIG_PATH)
PARAMETERS=$(cfn-toml params v2 -t $CONFIG_PATH)

aws cloudformation deploy \
    --stack-name $STACK_NAME \
    --s3-bucket $BUCKET \
    --region $REGION \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --tags group="cruddur-ddb" \
    --parameter-overrides $PARAMETERS \
    --capabilities CAPABILITY_NAMED_IAM
```



As always, we update CFN_PATH and CONFIG_PATH to reflect our DDB pathings. We now move back to our ddb template.yaml and begin implementing it. We access our existing ./bin/ddb/schema-load script to cross reference when creating our DDB template.yaml. First we start with our DynamoDB table, which we're calling DynamoDBTable:

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: |
  - DynaomDB Table
  - DynamoDB Stream
Parameters: 
Resources:
  DynamoDBTable:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-dynamodb-table.html
    Type: AWS::DynamoDB::Table
    Properties: 
      AttributeDefinitions: 
        - AttributeName: message_group_uuid
          AttributeType: S
        - AttributeName: pk
          AttributeType: S
        - AttributeName: sk
          AttributeType: S
      TableClass: STANDARD
      KeySchema: 
        - AttributeName: pk
          KeyType: HASH
        - AttributeName: sk
          KeyType: RANGE
      ProvisionedThroughput: 
        ReadCapacityUnits: 5
        WriteCapacityUnits: 5
      BillingMode: PROVISIONED
      DeletionProtectionEnabled: true
      GlobalSecondaryIndexes: 
        - IndexName: message-group-sk-index
          KeySchema: 
            - AttributeName: message_group_uuid
              KeyType: HASH
            - AttributeName: sk
              KeyType: RANGE
          Projection: 
            ProjectionType: ALL
          ProvisionedThroughput: 
            ReadCapacityUnits: 5
            WriteCapacityUnits: 5
      StreamSpecification:
        StreamViewType: NEW_IMAGE
```



Immediately, what’s different about this template from our others is the Transform: AWS::Serverless-2016-10-31 line. This line indicates that the template uses the AWS Serverless transform. It enables the use of SAM-specific resources and properties.


Here’s some information on the properties of DynamoDBTable:

AttributeDefinitions: This property defines the attribute definitions for the table. Each attribute definition consists of an AttributeName and its corresponding AttributeType. The AttributeName represents the name of the attribute, and the AttributeType represents the data type of the attribute (e.g., 'S' for string, 'N' for number, 'B' for binary).

TableClass: Specifies the class of the table. You can choose between STANDARD, which uses provisioned throughput, and PAY_PER_REQUEST, which uses on-demand capacity mode.

KeySchema: Defines the primary key schema for the table. The primary key consists of one or two attributes: the partition key (HASH) and an optional sort key (RANGE). The KeySchema property specifies the attribute names and their key types (either HASH or RANGE).

DeletionProtectionEnabled: Pretty self explanatory. Enables or disables deletion protection for the table. When deletion protection is enabled, the table cannot be deleted through normal CloudFormation stack updates or deletions.

GlobalSecondaryIndexes: This property allows you to define one or more global secondary indexes (aka GSIs) for the table. Each GSI has its own IndexName, KeySchema, Projection, and ProvisionedThroughput properties, similar to the primary key schema.

LocalSecondaryIndexes: Similar to GlobalSecondaryIndexes, this property enables you to define one or more local secondary indexes (aka LSIs) for the table. LSIs use the same partition key as the table but have a different sort key.

StreamSpecification: Configures the stream specification for the table. You can set the StreamViewType property to specify what information is included in the stream. Valid values for StreamViewType are NEW_IMAGE, OLD_IMAGE, NEW_AND_OLD_IMAGES, or KEYS_ONLY.

Moving on, we also define our serverless function, which we call ProcessDynamoDBStream. This is for our Lambda function. We use our existing one called cruddur-messaging-stream from AWS Lambda to cross reference:

```yaml
  ProcessDynamoDBStream:
    # https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-resource-function.html
    Type: AWS::Serverless::Function
    Properties:
      Handler: lambda_handler
      Runtime: python3.8
      Events:
        Stream:
          Type: DynamoDB
          Properties:
            Stream: !GetAtt DynamoDBTable.StreamArn
            BatchSize: 100
            StartingPosition: TRIM_HORIZON
```

We start with the policy, which we’re going to add inline to our role. We head over to IAM in AWS and reference our cruddur-messageing-stream-role that we created as the execution role for our existing cruddur-messageing-stream Lambda function. We allow ChatGPT to assist us, generating the policies from our existing ones attached to the cruddur-messageing-stream-role in AWS. Then we add it to the role:

```yaml
  LambdaLogGroup:
    Type: "AWS::Logs::LogGroup"
    Properties: 
      LogGroupName: "/aws/lambda/cruddur-messaging-stream"
      RetentionInDays: 14
  LambdaLogStream: 
    Type: "AWS::Logs::LogStream"
    Properties:
      LogGroupName: !Ref LambdaLogGroup
      LogStreamName: "LambdaExecution"
  ExecutionRole:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html
    Type: AWS::IAM::Role
    Properties: 
      RoleName: 'CruddurDdbStreamExecRole'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: 'Allow'
            Principal:
              Service: 'lambda.amazonaws.com'
            Action: 'sts:AssumeRole'
      Policies:            
        - PolicyName: "LambdaExecutionPolicy"
          PolicyDocument: 
            Version: "201-10-17"
            Statement: 
              - Effect: "Allow"
                Action: "logs:CreateLogGroup"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              - Effect: "Allow"
                Action:
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:${LambdaLogGroup}:*"
              - Effect: "Allow"
                Action: 
                  - "ec2:CreateNetworkInterface"
                  - "ec2:DeleteNetworkInterface"
                  - "ec2:DescribeNetworkInterfaces"
                Resource: "*"
              - Effect: "Allow"
                Action:
                  - "lambda:InvokeFunction"
                Resource: "*"
              - Effect: "Allow"
                Action:
                  - "dynamodb:DescribeStream"
                  - "dynamodb:GetRecords"
                  - "dynamodb:GetShardIterator"
                  - "dynamodb:ListStreams"
                Resource: "*"
```

LambdaLogGroup: This resource is of type AWS::Logs::LogGroup. It represents a CloudWatch Logs log group. It defines properties such as the LogGroupName, which is set to /aws/lambda/cruddur-messaging-stream, and RetentionInDays, which specifies that logs should be retained for 14 days.

LambdaLogStream: This represents a CloudWatch Logs log stream. It is associated with the LambdaLogGroup defined above.

ExecutionRole: This is our IAM role we're defining. You may notice the Service property is different from how we defined an sts:AssumeRole action in our service template.yaml. Instead of ecs-tasks.amazonaws.com, we're using lambda.amazonaws.com.

The policy portion defines the necessary permissions for the ExecutionRole to perform actions such as creating and managing CloudWatch Logs, working with network interfaces, invoking Lambda functions, and interacting with DynamoDB streams.

We now have to attach the role to our Lambda (serverless function). We also continue on adding more properties for the Lambda, cross referencing the existing one:

```yaml
  ProcessDynamoDBStream:
    # https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-resource-function.html
    Type: AWS::Serverless::Function
    Properties:
      Architectures: arm64
      CodeUri: ???
      Handler: lambda_handler
      Runtime: !Ref PythonRuntime
      Role: !GetAtt ExecutionRole.Arn
      Events:
        Stream:
          Type: DynamoDB
          Properties:
            Stream: !GetAtt DynamoDBTable.StreamArn
            BatchSize: 100
            StartingPosition: TRIM_HORIZON
```

While referencing our existing cruddur-messaging-stream Lambda, we noticed the Runtime was set to Python3.9 instead of 3.8. Since this is changing, we decided to add a parameter for that property instead and reference it.

```yaml
Parameters: 
  PythonRuntime: 
    Type: String
    Default: python3.9
```

We’ve added Architectures as a property. This will indicate that the function should be built for the arm64 architecture. We've also added CodeUri, which is the location of the function's code. Since we're not sure yet, we've set a placeholder of "???" for now.


Handler: lambda_handler: Specifies the name of the function's handler.

Events: Defines the events that trigger the function. In this case, it includes a single event named Stream of type DynamoDB, which triggers the function in response to DynamoDB stream records.

Type: DynamoDB: Indicates that the event source is a DynamoDB stream.

Stream: !GetAtt DynamoDBTable.StreamArn: Specifies the DynamoDB stream ARN that triggers the function. The !GetAtt function is retrieving the ARN of DynamoDBTable resource's stream using DynamoDBTable.StreamArn.

BatchSize: 100: Specifies the number of records to be processed in each batch. In this case, the function will process 100 records at a time.

StartingPosition: TRIM_HORIZON: Sets the starting position in the stream when the function is first deployed. TRIM_HORIZON indicates that the function should start processing from the oldest available records in the stream. This will process all available records.


We keep on, adding more properties to our lambda function, and editing some as we go:
```yaml
  ProcessDynamoDBStream:
    # https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-resource-function.html
    Type: AWS::Serverless::Function
    Properties:
      Architectures: arm64
      CodeUri: ???
      InlineCode: ???
      PackageType: ZIP
      Handler: lambda_handler
      Runtime: !Ref PythonRuntime
      Role: !GetAtt ExecutionRole.Arn
      MemorySize: !Ref MemorySize
      Timeout: !Ref Timeout
      Events:
        Stream:
          Type: DynamoDB
          Properties:
            Stream: !GetAtt DynamoDBTable.StreamArn
            # TODO - Does our Lambda handle more than one record?
            BatchSize: 1
            # https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-property-function-dynamodb.html#sam-function-dynamodb-startingposition
            # TODO - Is this the right value? 
            StartingPosition: LATEST
```


More info on the added properties:

We’re still not sure if we need to use CodeUri or InlineCode. We know because we need the PackageType property set to ZIP, one of these options will be used. With InlineCode, the property would allow us to provide the function's code directly as an inline string.

PackageType: ZIP: The PackageType property specifies the type of packaging for the function's code. In this case, it is set to ZIP, indicating that the code will be packaged as a ZIP file. This is the most common packaging type for Lambda functions.

MemorySize: !Ref MemorySize: Defines the amount of memory allocated to the function during execution.

Timeout: !Ref Timeout: The Timeout property specifies the maximum execution time for the function in seconds.

We’ve updated the BatchSize property to 1 instead of 100, as it was set before. This property sets the number of records to be processed in each batch.

We’ve also updated StartingPosition from TRIM_HORIZON to LATEST. This property determines the starting position in the DynamoDB stream when the function is first deployed. Setting it to LATEST instructs the function to start processing from the most recent record in the stream. This ensures that the function consumes only the new records that arrive after deployment. As you can see from our comments, we're questioning if this is correct at this time.

We also add parameters for the MemorySize and Timeout properties.

```yaml
  MemorySize:
   Type: Number
   Default: 128
 Timeout: 
   Type: Number
   Default: 3
```


Our Lambda is starting to look better, so we direct our attention towards implementing SAM into our DDB layer. We need to install it into our workspace, so we open our .gitpod.yml file and add it:

```yaml
tasks:
 - name: aws-sam
   init: |
     cd /workspace
     wget https://github.com/aws/aws-sam-cli/releases/latest/download/aws-sam-cli-linux-x86_64.zip
     unzip aws-sam-cli-linux-x86_64.zip -d sam-installation
     sudo ./sam-installation/install
     cd $THEIA_WORKSPACE_ROOT
```

So we don’t have to restart our workspace, we run these commands line by line in our terminal to install SAM into our current environment. With that completed, we now are deciding how we want to implement SAM. We check through the CLI to see what is available from SAM by just typing SAM:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/ec5e3977-1c86-4734-94ab-903199743beb)


We know we want to use the build command, so we head back over to our ddb-deploy script and clear it, as the CFN commands we've set here aren't going to work for SAM. We also know we're going to need the sam package and sam deploy commands so we add them both:

```sh
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-build.html
sam build 

# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-package.html
sam package 

# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-deploy.html
sam deploy
```

From here, we work through the script, adding options for the commands, staring with sam build:

```yaml
# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-build.html
sam build \
--template \
--parameter-overrides
--build-dir
--base-dir
--region $AWS_DEFAULT_REGION
```

These are defaults that we copied over from documentation thus far. We manually run the command for sam build from the terminal, and receive an error to see what it's asking for:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/80590771-f333-4b63-9425-7daee2073e1c)


Our existing function sits in ./aws/lambdas as cruddur-messaging-stream.py. We create a new folder in the ./aws/lambdas directory named cruddur-messaging-stream, then move the existing function file to the folder. We then rename the file to lambda-function.py to match what it's named in AWS. We get the path to the file, and add it as a variable named FUNC_PATH to our ddb-deploy script.

```
FUNC_DIR="/workspace/aws-bootcamp-cruddur-2023/aws/lambdas/cruddur-messaging-stream/"
```

```yaml
# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-build.html
sam build \
--template \
--parameter-overrides
--build-dir $FUNC_DIR
--base-dir $FUNC_DIR
--region $AWS_DEFAULT_REGION 
```

We comment out our other commands from the script, then attempt to run it:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/a890eec7-5447-484a-91c0-c9990ad0dc61)

With that error, we need to add another variable for our template path, so we do. Then we implement the variable as well. We also comment out our --parameter-overrides option for now and add another variable for our SAM configuration path, adding an option for it too.

```yaml
FUNC_DIR="/workspace/aws-bootcamp-cruddur-2023/aws/lambdas/cruddur-messaging-stream/"
TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/config.toml"

# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-build.html
sam build \
--config $CONFIG_PATH \
--template $TEMPLATE_PATH \
--build-dir $FUNC_DIR \
--base-dir $FUNC_DIR \
--region $AWS_DEFAULT_REGION 
#--parameter-overrides
```

We run the script again, not expecting it to work, just seeing what else we need to add. Here’s the error output:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/8702a9ae-33dc-447f-9b00-30031dac86f8)

We correct the error by editing our option for the configuration file.

```yaml
FUNC_DIR="/workspace/aws-bootcamp-cruddur-2023/aws/lambdas/cruddur-messaging-stream"
TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/config.toml"

# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-build.html
sam build \
--config-file $CONFIG_PATH \
--template $TEMPLATE_PATH \
--build-dir $FUNC_DIR \
--base-dir $FUNC_DIR \
--region $AWS_DEFAULT_REGION 
#--parameter-overrides
```


We again run the script:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/a57a745c-8c16-48d8-be74-c6133fc7d20a)

This is because our existing config.toml in the ./aws/cfn/ddb directory is empty. We consult AWS documentation for reference.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/7876d685-b64e-41c1-bcf0-68d564e17262)

In a SAM configuration file, you can set different parameters for different SAM commands. With a good point of reference, we begin implementing our config.toml using the SAM configuration structure, setting parameters for each of our SAM commands:



```yaml
version=0.1
[default.build.parameters]
region = "us-east-1"

[default.package.parameters]
region = "us-east-1"

[default.deploy.parameters]
region = "us-east-1"
```

Since we’re setting the region parameter here, we remove it from our ddb-deploy script.

```yaml
# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-build.html
sam build \
--config-file $CONFIG_PATH \
--template-file $TEMPLATE_PATH \
--base-dir $FUNC_DIR 
# --parameter-overrides
```
We run ddb-deploy again:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/0638aabe-0880-47c0-a7aa-274cf683a832)

We’re told from the terminal that the build succeeded, so we go in search of the artifacts and template files it built. Our build.toml file that was auto-generated was placed into our ./aws/lambdas directory.



![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/f78f12ee-8e36-4a70-b4e6-915f60fc7010)

This wasn’t the intended result, so we check Source Control from our workspace and discard the changes, deleting the file.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/c8ff99af-a9ed-4b77-828f-3f2e25b3d597)

We adjust the FUNC_DIR pathing in our ddb-deploy script, adding a / to the end of the path.

```yaml
FUNC_DIR="/workspace/aws-bootcamp-cruddur-2023/aws/lambdas/cruddur-messaging-stream/"
```

Then run the ddb-deploy script again. The build succeeds again. This makes no difference. The build.toml file is placed into the same location as before. This leads us to adjusting our .gitignore file, so this file does not persist within our environment.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/f1c5461d-9ce3-414e-aa77-7079f3df2177)

We move on, now working on the sam package command in the ddb-deploy script:

```yaml
FUNC_DIR="/workspace/aws-bootcamp-cruddur-2023/aws/lambdas/cruddur-messaging-stream/"
TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/config.toml"
ARTIFACT_BUCKET="jh-cfn-artifacts"

# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-build.html
sam build \
--config-file $CONFIG_PATH \
--template-file $TEMPLATE_PATH \
--base-dir $FUNC_DIR 
# --parameter-overrides 

# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-package.html
sam package \
  --s3-bucket $ARTIFACT_BUCKET \
  --config-file $CONFIG_PATH \
  --template-file $TEMPLATE_PATH \
```

We run our ddb-deploy script again, and the build completes. Here's the output from the sam package command portion:



![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/21e59a32-c104-4354-998b-2982bac7b362)

We run our ddb-deploy script again, and the build completes. Here's the output from the sam package command portion:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/671ed798-f5c4-4822-a149-cacf31ac9db8)

The output is spit out in the terminal (which is a CFN template) because we haven’t told it to dump this information somewhere yet. We move over to S3 in AWS, checking our jh-cfn-artifacts bucket to see if the template was uploaded. It was not. We need to specify where the template file is written so it doesn't default to the standard output.

We comment out the option from our sam build command in the script for --base-dir and run the script again:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/d24cb149-5536-44b1-a9fa-48ac858efce8)

This updates our directory where the artifacts are built to, so we remove the --base-dir option altogether. We can see the the build directory and the template.yaml file generated are now going to the correct location:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/4947a0d5-95a7-4e41-a6cb-18dbe7c1ac32)

We can now continue working on the sam package command in our ddb-deploy script. We add variables for the sam package command, specifying a new value for TEMPLATE_PATH to match the location generated by the sam build command, and OUTPUT_TEMPLATE_PATH to specify the path for the outputted packaged.yaml file. Next, we add an option for the --output-template-file and use the new variable. We also add an option to give an S3 prefix:

```sh
TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/.aws-sam/build/template.yaml"
OUTPUT_TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/.aws-sam/build/packaged.yaml"

# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-package.html
sam package \
  --s3-bucket $ARTIFACT_BUCKET \
  --config-file $CONFIG_PATH \
  --output-template-file $OUTPUT_TEMPLATE_PATH \
  --template-file $TEMPLATE_PATH \
  --s3-prefix "ddb"
```

We test the ddb-deploy script again:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/f25e1354-25d0-4e41-ac7c-92d7070a4386)

We’re now able to begin working on the sam deploy portion of the script. We want to make use of the pathing for the new packaged.yaml file, as this is what will be deployed. We add another variable for this path named PACKAGED_TEMPLATE_PATH. We then implement the rest of the options for the sam deploy command:

```yaml
PACKAGED_TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/.aws-sam/build/packaged.yaml"

# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-deploy.html
sam deploy \
  --template-file $PACKAGED_TEMPLATE_PATH \
  --config-file $CONFIG_PATH \  
  --stack-name "CrdDdb"\
  --tags group="cruddur-ddb" \
  --capabilities "CAPABILITY_IAM"
```

We test the ddb-deploy script again. The build and package steps complete, and deployment is initiated. From the terminal, we can see a changeset is waiting to be created.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/6e0e4719-f7ac-421e-a501-73f83ece6b97)

The changeset fails to create. We decide to try running the sam validatecommand to validate our template.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/b43d2ea1-d40c-4a4a-bea9-87bdb0ce3804)

This command is so useful, we decide to add it to our ddb-deploy script to run before any of our other commands in the script.

```
sam validate -t $TEMPLATE_PATH
```

With the error, we head back over to our ./aws/cfn/ddb/template.yaml and find that we're still missing values for some properties in our function. Other properties need adjusted as well.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/0f93adcb-bbcb-49cb-b2b1-90c4d3112552)

We make adjustments, specifically removing the InlineCode property. We update the case-sensitive value for ZIP to Zip, and also provide a path for CodeUri.

```
  # https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-resource-function.html
    Type: AWS::Serverless::Function
    Properties:
      Architectures: arm64
      CodeUri: .
      PackageType: Zip
      Handler: lambda_handler
      Runtime: !Ref PythonRuntime
      Role: !GetAtt ExecutionRole.Arn
```

We test ddb-deploy again:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/6854c9a0-9382-474a-9d05-91ed6014dae7)

We adjust our Architectures property to use a list instead:

```
    # https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-resource-function.html
    Type: AWS::Serverless::Function
    Properties:
      Architectures: 
        - arm64
      CodeUri: .
      PackageType: Zip
      Handler: lambda_handler
      Runtime: !Ref PythonRuntime
      Role: !GetAtt ExecutionRole.Arn
```

Then we run ddb-deploy again:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/6d8e1ccf-10f8-4e15-a1cf-1aff5e6fbc63)

Andrew let’s us know that this error indicates we may want to run this in a container. That way we can install dependencies required for our Lambda function. For this, we add the --use-container option to our ddb-deploy script for the sam build command.


```
sam validate -t $TEMPLATE_PATH

# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-build.html
# --use-container
# use container is for building the lambda in a container
# its still using the runtimes and its not a custom runtime
sam build \
--use-container \
--config-file $CONFIG_PATH \
--template-file $TEMPLATE_PATH \
--base-dir $FUNC_DIR 
```

We again run our ddb-deploy script. The script hangs while mounting the container.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/b1ba2f90-c6f9-411d-8044-954a90b537b1)

We update template.yaml to remove Architectures property so it defaults to x86 instead of arm64 like we were specifying, as Andrew was able to find other users with the same issue online and this resolved the problem.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/ffb63fd0-cf05-4a08-9fbc-a904dd8bec83)

We also go to update the CodeUri property as well, as others were having issues with the pathing specified there. When we navigate to the ./aws/lambdas/cruddur-messaging-stream directory (pathing for our Lambda function), we only have a template.yaml file in there.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/92ddd283-6f30-4e07-975f-4707f1c23a4b)

We have to go back into our previous commits to copy the file back into our workspace, placing the lambda-function.py file back into the ./aws/lambdas/cruddur-messaging-stream directory. Then we delete the template.yaml file in the same directory.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/7900484f-d6a8-4145-9456-330b4af6116a)


```
    # https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-resource-function.html
    Type: AWS::Serverless::Function
    Properties:
      CodeUri: aws/lambdas/cruddur-messaging-stream
      PackageType: Zip
      Handler: lambda_handler
      Runtime: !Ref PythonRuntime
      Role: !GetAtt ExecutionRole.Arn
```

We again run the ddb-deploy script, and we pass the build step, then the package step. Before checking if the deploy finished or not, we navigate to the .aws-sam/build/template.yaml to see what was generated out:




![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/3c1830b7-b0ba-4192-8c47-3cbf29417865)

This is not what we specified for CodeUri but that's what it replaced it with. When we check the packaged.yaml file generated, the CodeUri value shows a path for our S3 bucket, cfn-artifacts-1, using the ddb prefix we set in the script. Here's a screenshot from Andrew's packaged.yaml for reference:




![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/9c76665e-0573-42a9-ab7e-6fb7f4ec3c59)

That being said, it looks like our deployment did not succeeed, as there’s an error when creating the changeset:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/9a878d94-8125-4050-8d5f-18ff56e86a86)

We fix the error by updating the --capabilities option of our sam deploy command to the correct value in ddb-deploy:

```
# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-deploy.html
sam deploy \
  --template-file $PACKAGED_TEMPLATE_PATH \  
  --config-file $CONFIG_PATH \
  --stack-name "CrdDdb"\
  --tags group="cruddur-ddb" \
  --capabilities "CAPABILITY_NAMED_IAM"
```

Instead of running the ddb-deploy script again, we decide to break each command up into its own script. We create a new folder in the ./bin directory named sam. Then within sam, we create another new folder named ddb. We then create 3 new scripts within the ./bin/sam/ddb directory for each command: build, deploy, and package. Then, we go ahead and break up the ddb-deploy script, putting each command into it's corresponding script:

./bin/sam/ddb/build

```
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

FUNC_DIR="/workspace/aws-bootcamp-cruddur-2023/aws/lambdas/cruddur-messaging-stream/"
TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/config.toml"

sam validate -t $TEMPLATE_PATH

echo "== build"
# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-build.html
# --use-container
# use container is for building the lambda in a container
# its still using the runtimes and its not a custom runtime
sam build \
--use-container \
--config-file $CONFIG_PATH \
--template-file $TEMPLATE_PATH \
--base-dir $FUNC_DIR 
# --parameter-overrides 
```

./bin/sam/ddb/deploy

```
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

PACKAGED_TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/.aws-sam/build/packaged.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/config.toml"

echo "== deploy"
# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-deploy.html
sam deploy \
  --template-file $PACKAGED_TEMPLATE_PATH \
  --config-file $CONFIG_PATH \
  --stack-name "CrdDdb"\
  --tags group="cruddur-ddb" \
  --capabilities "CAPABILITY_NAMED_IAM"
```

./bin/sam/ddb/package

```
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/.aws-sam/build/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/config.toml"
OUTPUT_TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/.aws-sam/build/packaged.yaml"
ARTIFACT_BUCKET="cfn-artifacts-1"

echo "== package"
# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-package.html
sam package \
  --s3-bucket $ARTIFACT_BUCKET \
  --config-file $CONFIG_PATH \
  --output-template-file $OUTPUT_TEMPLATE_PATH \
  --template-file $TEMPLATE_PATH \
  --s3-prefix "ddb"
```

We make each script executable, then run each one individually, making sure they work. All is well until the deploy script. Our changeset is created successfully, but it executes the changeset on its own and fails.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/bc1eefd7-16c9-4477-97b8-5218e93b37e6)

We fix this by adding the option --no-execute-changeset to our deploy script:

```
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

PACKAGED_TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/.aws-sam/build/packaged.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/ddb/config.toml"

echo "== deploy"
# https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-deploy.html
sam deploy \
  --template-file $PACKAGED_TEMPLATE_PATH \
  --config-file $CONFIG_PATH \
  --stack-name "CrdDdb"\
  --tags group="cruddur-ddb" \
  --no-execute-changeset \  
  --capabilities "CAPABILITY_NAMED_IAM"

```

We then remove the ddb-deploy script, as we no longer need it. The error also indicated that the LambdaLogGroup using property LogGroupName: "/aws/lambda/cruddur-messaging-stream" already exists, so we update the LogGroupName to "/aws/lambda/cruddur-messaging-stream00" in our DDB template. Then we head back over to CloudFormation in AWS and try deleting the DDB stack, but it fails to delete. The DDB table we were creating had Deletion protection enabled, so it won't delete. From our DDB template, we add a parameter for DeletionProtectionEnabled setting the value to false:

```
  DeletionProtectionEnabled:
    Type: String
    Default: false
```
Then we reference the parameter for the property in the DDB table:
```
      DeletionProtectionEnabled: !Ref DeletionProtectionEnabled
```

From there, we head over to DynamoDB in AWS, and turn off deletion protection for the table:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/5ea75871-0a95-4752-b186-27585845a9b1)

Then we navigate back to CFN and delete the DDB stack:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/8696176a-23c2-472c-83fb-bfe2fadfbd86)

Back over in our workspace, we again run all 3 scripts: build, package, deploy:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/d7c4bdff-5f0b-4d95-a0a6-f94c08db143f)


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/8656b44f-a819-4957-a445-fb5b582edc8e)

The error indicates the .zip file uploaded to CloudFormation is empty. We check this by heading over to S3, and access the cfn-artifacts-1 bucket, navigating to the ddb folder inside. There's a file (or folder) here, so we download it, then add a .zip file extension to it. The folder is most definitely empty:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/0c461fff-5778-4eb9-8068-61f1c8a6e970)

We go ahead and empty the cfn-artifacts-` bucket as it was getting quite full. For a better way of keeping this bucket organized, we decide to add the --s3-prefix option/flag to each of our scripts.

```
      --s3-prefix cluster \
    
      --s3-prefix db \
    
      --s3-prefix networking \
      
      --s3-prefix backend-service \
```

We also initially thought that the Lambda function in our DDB template.yaml would run relative to where the template.yaml file was located. To test this, we move the cruddur-messaging-stream folder containing our lamba_function.py file out of the ./aws/lambdas directory, and into the ./aws/cfn/ddb directory. Then, we update the CodeUri value in the DDB template file to reflect the change:

```
  CodeUri: cruddur-messaging-stream
```

We run our build script to test, just to see where our SAM generated template is building out. The value for CodeUri in our generated template.yaml appears to be what's being built, and it's being built in the .aws-sam/build directory.

We delete the folder that’s being built out to test for sure. Then we run the build script again. The ProcessDynamoDBStream folder IS being created. We expand the folder:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/cbfb4ffa-e37b-4fe0-9f96-685ea3c14c29)

Its empty. This is our problem. Further into troubleshooting, we move the cruddur-messaging-stream folder containing our function that we moved earlier into the top level root directory of our workspace.




![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/7a92e441-6025-49c0-87b2-5d0003714cde)

Then we update the CodeUri property in ./aws/cfn/ddb/template.yaml to cruddur-messaging-stream


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/fb93329c-6202-439b-805e-5d284d04b462)


We again run the build script and get the same results as before. Andrew confirms that this means the CodeUri property isn't relative to where the template.yaml file is located. We decide to create a new root level folder named ddb, then we move all of our DDB scripts, template.yaml, config.toml, our cruddur-messaging-stream folder containing lamba_function.py, and all other dependencies into the root level ddb folder. Next, we delete the sam/ddb folders from the root directory, as they're now empty.



![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/051d8dbd-5464-4809-8c91-0594bcfbaa6b)

We update the pathing to our variables in our build, package, and deploy scripts:

```
FUNC_DIR="/workspace/aws-bootcamp-cruddur-2023/ddb/cruddur-messaging-stream/"
TEMPLATE_PATH="/workspace/aws-bootcamp-cruddur-2023/ddb/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/ddb/config.toml"
```

When we try our build script again, we find that it's creating an empty cruddur-messaging-stream folder within our existing one:



![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/bc5cf608-7b74-4702-af69-c50ea11a410e)

The .aws-sam/build/ProcessDynamoDBStream folder is also generated and empty still. We remove the created folders, and since we're getting prompts for it while running the build script, we add an empty requirements.txt file inside of the cruddur-messaging-stream folder. Then we run our build script again. It again creates the cruddur-messaging-stream folder inside the existing one. The empty requirements.txt we added made no difference either:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/67d84458-e4e4-43e1-bd76-df507d30173e)

We delete the duplicate cruddur-messaging-stream folder, rename the existing one to function, then updated the FUNC_DIR variable in our build script:

```
FUNC_DIR="/workspace/aws-bootcamp-cruddur-2023/ddb/function"
```

We then go back to the DDB template.yaml and update the CodeUri property again:

      CodeUri: .

From there, since it’s not doing anything, we remove the requirements.txt file we created earlier from the ./ddb/function directory that it resided in. We try our build script again and it completes. We know it worked because we have lambda_function.py in the .aws-sam/build directory:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/11c246b7-ca96-4385-af67-ad2ce8cde4ae)

We continue on, running our package script.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/7a73a735-e0ba-4744-9815-cab460c2618a)

Before we run the deploy script, we check CloudFormation for the DDB stack:


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/3cace0b7-6ca8-4221-8eab-1e63601d30f9)

Since it never has completed successfully, we won’t be able to run the deploy script yet. We delete the stack from CFN, THEN run the deploy script. Our changeset is created successfully.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/9fc71392-1d13-479e-9cc7-d7359d0e4a0b)

We execute the changeset from CloudFormation and wait for it to complete. The DDB stack shows a status of CREATE_COMPLETE.


![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/e6058d33-4593-4a50-b838-51afc57a3d85)

This puts our DDB layer in a good state for now. We are now ready to move onto the CICD layer.




![Screenshot 2024-03-24 051106](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/3f5f7429-f83f-4d68-a660-762add52cb2f)



Starting CICD Layer

# CICD Layer
To start off the CICD layer, we start off with the script. We create a new one in the ./bin/cfn directory named cicd-deploy, then copy the networking-deploy script to use as a basis. As always, we adjust the pathing for our CFN_PATH and CONFIG_PATH variables then update the --s3-prefix and --tags group flags to --s3-prefix cicd \ and --tags group="cruddur-cicd" \ respectively.

```sh
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/cicd/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/cicd/config.toml"

cfn-lint $CFN_PATH

BUCKET=$(cfn-toml key deploy.bucket -t $CONFIG_PATH)
REGION=$(cfn-toml key deploy.region -t $CONFIG_PATH)
STACK_NAME=$(cfn-toml key deploy.stack_name -t $CONFIG_PATH)

aws cloudformation deploy \
    --stack-name $STACK_NAME \
    --s3-bucket $BUCKET \
    --s3-prefix cicd \
    --region $REGION \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --tags group="cruddur-cicd" \
    --capabilities CAPABILITY_NAMED_IAM
```

Next, we move over to the ./aws/cfn directory and create a cicd folder, placing a new template.yaml and config.toml file in the folder. We populate config.toml, defining no parameters:

```
[deploy]
bucket = 'cfn-artifacts-1'
region = 'us-east-1'
stack_name = 'CrdCicd'
```

We next start implementing the template.yaml. We already know what parameters we're going to need, so we begin defining these:

```yaml
AWSTemplateFormatVersion: 2010-09-09
Description: |
  - CodeStar Connection V2 Github
  - CodePipeline
  - CodeBuild
Parameters:
  GitHubBranch: 
    Type: String
    Default: prod
  GithubRepo: 
    Type: String
    Default: 'bhanumalhotra123/aws-bootcamp-cruddur-2023'
  ClusterStack:
    Type: String
  ServiceStack:
    Type: String
Resources:
```

Its decided that we’d like to use a nested stack to implement the CICD layer. Andrew explains that when you have a codebuild.yaml file that you'd like to use over and over again, that's what you'd use, is a nested stack. 


```
Resources: 
  CodeBuildBakeImageStack:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-stack.html
    Type: AWS::CloudFormation::Stack
    Properties: 
      TemplateURL: nested/codebuild.yaml
```

With the TemplateURL defined, we go ahead and create the path by adding a new folder named nested to the ./aws/cfn/cicd directory. Then we create the codebuild.yaml file inside. 

```yaml
AWSTemplateFormatVersion: 2010-09-09
Description: |
  Codebuild used for baking container images
  - Codebuild  Project
  - Codebuild Project Role
Parameters: 
  LogGroupPath:
    Type: String
    Description: "The log group path for CodeBuild"
    Default: "/cruddur/codebuild/bake-service"
  LogStreamName:
    Type: String
    Description: "The log group path for CodeBuild"
    Default: "backend-flask"    
  CodeBuildImage: 
    Type: String
    Default: aws/codebuild/amazonlinux2-x86_64-standard:4.0
  CodeBuildComputeType:
    Type: String
    Default: BUILD_GENERAL1_SMALL
  CodeBuildTimeoutMins:
    Type: Number
    Default: 5
  BuildSpec:
    Type: String
    Default: 'buildspec.yaml'
Resources: 
  CodeBuild:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-codebuild-project.html
    Type: AWS::CodeBuild::Project
    Properties:
      QueuedTimeoutInMinutes: !Ref CodeBuildTimeoutMins
      ServiceRole: !GetAtt CodeBuildRole.Arn
      # PrivilegedMode is needed to build Docker images
      # even though we have No Artifacts, CodePipeline Demands both to be set as CODEPIPLINE
      Artifacts:
        Type: CODEPIPELINE
      Environment:
        ComputeType: !Ref CodeBuildComputeType
        Image: !Ref CodeBuildImage
        Type: LINUX_CONTAINER
        PrivilegedMode: true
      LogsConfig:
        CloudWatchLogs:
          GroupName: !Ref LogGroupPath
          Status: ENABLED
          StreamName: !Ref LogStreamName
      Source:
        Type: CODEPIPELINE
        BuildSpec: !Ref BuildSpec
  CodeBuildRole:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action: ['sts:AssumeRole']
          Effect: Allow
          Principal:
            Service: [codebuild.amazonaws.com]
        Version: '2012-10-17'
      Path: /
      Policies:
        - PolicyName: !Sub ${AWS::StackName}ECRPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action:
                - ecr:BatchCheckLayerAvailability
                - ecr:CompleteLayerUpload
                - ecr:GetAuthorizationToken
                - ecr:InitiateLayerUpload
                - ecr:BatchGetImage
                - ecr:GetDownloadUrlForLayer
                - ecr:PutImage
                - ecr:UploadLayerPart
                Effect: Allow
                Resource: "*"
        - PolicyName: !Sub ${AWS::StackName}VPCPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action:
                - ec2:CreateNetworkInterface
                - ec2:DescribeDhcpOptions
                - ec2:DescribeNetworkInterfaces
                - ec2:DeleteNetworkInterface
                - ec2:DescribeSubnets
                - ec2:DescribeSecurityGroups
                - ec2:DescribeVpcs
                Effect: Allow
                Resource: "*"
              - Action:
                - ec2:CreateNetworkInterfacePermission
                Effect: Allow
                Resource: "*"
        - PolicyName: !Sub ${AWS::StackName}Logs
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action:
                - logs:CreateLogGroup
                - logs:CreateLogStream
                - logs:PutLogEvents
                Effect: Allow
                Resource:
                  - !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:${LogGroupPath}*
                  - !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:${LogGroupPath}:*
Outputs:
  CodeBuildProjectName:
    Description: "CodeBuildProjectName"
    Value: !Sub ${AWS::StackName}Project
```


A lot of the properties defined here are quite self explanatory, but I’ll dig a bit deeper here:

LogGroupPath: Represents the log group path for CodeBuild. It allows you to specify the desired log group path where the CodeBuild logs will be stored.

LogStreamName: Represents the log stream name for CodeBuild. It allows you to specify the name of the log stream where the CodeBuild logs will be written.

CodeBuildImage: Specifies the Docker image to be used for CodeBuild.

CodeBuildComputeType: Specifies the compute type for CodeBuild. It determines the resources allocated to the CodeBuild project during the build process.

CodeBuildTimeoutMins: This specifies the timeout duration for CodeBuild in minutes. If the build process exceeds this timeout, it will be terminated.

The CodeBuildRole we specified grants the necessary permissions to interact with ECR, VPC resources, and manage logs. Finally, the output provides access to the CodeBuild project name for further use in other parts of our infrastructure if needed.

This should completely flesh out our codebuild.yaml. We move back over to our CICD template.yaml file and continue adding resources, starting with a CodeStar Connection. This resource is a service that will enable us to connect and manage resources in GitHub.

```yaml
  CodeStarConnection:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-codestarconnections-connection.html
    Type: AWS::CodeStarConnections::Connection
    Properties: 
      ProviderType: GitHub
```

No properties defined here. ProviderType indicates we're building a CodeStar connection to connect us to our GitHub repository.

We’re now ready to begin working on the pipeline resource. We implement this in our CICD template, including all 3 stages; source, build, deploy:
```yaml
  Pipeline:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-codepipeline-pipeline.html
    Type: AWS::CodePipeline::Pipeline
    Properties: 
      RoleArn: !GetAtt CodePipelineRole.Arn
      Stages:
        - Name: Source
          Actions:
            - Name: ApplicationSource
              RunOrder: 1
              ActionTypeId:
                Category: Source
                Provider: CodeStarSourceConnection
                Owner: AWS
                Version: '1'
              OutputArtifacts:
                - Name: Source
              Configuration: 
                ConnectionArn: !Ref CodeStarConnection
                FullRepositoryId: !Ref GithubRepo
                BranchName: !Ref GitHubBranch
                OutputArtifactFormat: "CODE_ZIP"
        - Name: Build
          Actions: 
            - Name: BuildContainerImage
              RunOrder: 1
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              InputArtifacts:
                - Name: Source
              OutputArtifacts:
                - Name: ImageDefinition
              Configuration:
                ProjectName: !GetAtt CodeBuildBakeImageStack.Outputs.CodeBuildProjectName
                BatchEnabled: false
        # https://docs.aws.amazon.com/codepipeline/latest/userguide/action-reference-ECS.html                
        - Name: Deploy
          Actions:
            - Name: Deploy
              RunOrder: 1
              ActionTypeId: 
                Category: Deploy
                Provider: ECS
                Owner: AWS
                Version: '1'
              InputArtifacts: 
                - Name: ImageDefinition
              Configuration: 
                # In Minutes
                DeploymentTimeout: "10"
                ClusterName: 
                  Fn::ImportValue:
                    !Sub ${ClusterStack}ClusterName
                ServiceName: 
                  Fn::ImportValue:
                    !Sub ${ServiceStack}ServiceName 
```

Let me provide some information on the various properties of the stages:

RunOrder: This property determines the order in which actions are executed within a stage.

ActionTypeId: This property identifies the type of action to be performed.

Category: This property specifies the category of the action. In this case, the category can be "Source", "Build", or "Deploy" depending on the stage.

Provider: This property specifies the provider of the action. For example, "CodeStarSourceConnection" for the source stage, "CodeBuild" for the build stage, and "ECS" for the deploy stage.

Owner: This property specifies the owner of the action. In this case, it is set to "AWS" indicating that the action is provided by AWS.

Version: This property specifies the version of the action.

InputArtifacts: This property specifies the input artifacts for the action. These artifacts are typically generated by previous actions in the pipeline.

OutputArtifacts: This property specifies the output artifacts produced by the action. These artifacts can be used as input by subsequent actions.

Configuration: This property contains the configuration settings for the action. The specific configuration properties depend on the action type.

For the ServiceName property, we are importing the value of the ServiceName property from our service layer. We need to go back to our service template.yaml and add this as an Output to export:

```
Outputs:
  ServiceName:
    Value: !GetAtt FargateService.Name
    Export:
      Name: !Sub "${AWS::StackName}ServiceName"
```


With this output added, we need to make it available to our CICD layer. We redeploy the service layer, running the service-deploy script. Then, we execute the changeset from CFN. The output is added:
![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/b73ef4fe-4038-4b9f-a7f8-5667508436ff)




You may have also noticed we’re already getting the ARN attribute from CodePipelineRole to define the value for RoleArn in the pipeline. We can now define this role in the CICD template.yaml. We also use the inline policy to define the permissions of the role, much as we've done a few times thus far:


```
  CodePipelineRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action: ['sts:AssumeRole']
          Effect: Allow
          Principal:
            Service: [codepipeline.amazonaws.com]
        Version: '2012-10-17'
      Path: /
      Policies:
        - PolicyName: !Sub ${AWS::StackName}EcsDeployPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action:
                - ecs:DescribeServices
                - ecs:DescribeTaskDefinition
                - ecs:DescribeTasks
                - ecs:ListTasks
                - ecs:RegisterTaskDefinition
                - ecs:UpdateService
                Effect: Allow
                Resource: "*"
        - PolicyName: !Sub ${AWS::StackName}CodeStarPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action:
                - codestar-connections:UseConnection
                Effect: Allow
                Resource:
                  !Ref CodeStarConnection
        - PolicyName: !Sub ${AWS::StackName}CodePipelinePolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action:
                - s3:*
                - logs:CreateLogGroup
                - logs:CreateLogStream
                - logs:PutLogEvents
                - cloudformation:*
                - iam:PassRole
                - iam:CreateRole
                - iam:DetachRolePolicy
                - iam:DeleteRolePolicy
                - iam:PutRolePolicy
                - iam:DeleteRole
                - iam:AttachRolePolicy
                - iam:GetRole
                - iam:PassRole
                Effect: Allow
                Resource: '*'
        - PolicyName: !Sub ${AWS::StackName}CodePipelineBuildPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action:
                - codebuild:StartBuild
                - codebuild:StopBuild
                - codebuild:RetryBuild
                Effect: Allow
                Resource: !Join
                  - ''
                  - - 'arn:aws:codebuild:'
                    - !Ref AWS::Region
                    - ':'
                    - !Ref AWS::AccountId
                    - ':project/'
                    - !GetAtt CodeBuildBakeImageStack.Outputs.CodeBuildProjectName  
```

With this role, we’re granting permissions for CodePipeline to perform tasks such as deploying ECS services, using CodeStar connections, accessing S3 buckets, managing CloudFormation stacks, and interacting with IAM roles and policies. It allows CodePipeline to describe and manipulate ECS services and task definitions, start and stop CodeBuild projects, and create and manage IAM roles.

We now need to go back and update our CICD config.toml to pass the parameters we added to our CICD template.yaml.

```yaml
[deploy]
bucket = 'cfn-artifacts-1'
region = 'us-east-1'
stack_name = 'CrdCicd'

[parameters]
ServiceStack = 'CrdSrvBackendFlask'
ClusterStack = 'CrdCluster'
GitHubBranch = 'prod'
GithubRepo = 'aws-bootcamp-cruddur-2023'


```

We might be ready to deploy. To test, we make our cicd-deploy script exectuable, then run it.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/0efbd42b-f493-4094-b694-a92c8b5fccc1)

To fix the first error received, we go back to our CICD template.yaml file and define the ConnectionName property of the CodeStarConnections::Connection.

```
    Type: AWS::CodeStarConnections::Connection
    Properties: 
      ConnectionName: !Sub ${AWS::StackName}-connection    
      ProviderType: GitHub
```

We will need to add an S3 bucket to fix the 3rd error. We decide to do this manually, navigating to S3 in AWS named 
codepipeline-cruddur-artifacts-1 .


Then we went back to our workspace and added a parameter for our ArtifactBucketName to our config.toml and template.yaml.

```
[deploy]
bucket = 'cfn-artifacts-1'
region = 'us-east-1'
stack_name = 'CrdCicd'

[parameters]
ServiceStack = 'CrdSrvBackendFlask'
ClusterStack = 'CrdCluster'
GitHubBranch = 'prod'
GithubRepo = 'aws-bootcamp-cruddur-2023'
ArtifactBucketName = 'codepipeline-cruddur-artifacts-1'

```
```
  ArtifactBucketName:
    Type: String   

```
Next we added an ArtifactStore property to our pipeline:

```
  Pipeline:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-codepipeline-pipeline.html
    Type: AWS::CodePipeline::Pipeline
    Properties: 
      ArtifactStore:
        Location: !Ref ArtifactBucketName
        Type: S3
```
We run cicd-deploy one more time:

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/b5bf3e7b-a5a6-4d1b-b976-255b31e751c2)

To try and fix this error, we added an aws cloudformation package command to the cicd-deploy script:

```
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/cicd/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/cicd/config.toml"
PACKAGED_PATH="/workspace/aws-bootcamp-cruddur-2023/tmp/packaged-template.yaml"
PARAMETERS=$(cfn-toml params v2 -t $CONFIG_PATH)
echo $CFN_PATH

cfn-lint $CFN_PATH

BUCKET=$(cfn-toml key deploy.bucket -t $CONFIG_PATH)
REGION=$(cfn-toml key deploy.region -t $CONFIG_PATH)
STACK_NAME=$(cfn-toml key deploy.stack_name -t $CONFIG_PATH)

# package
# -----------------
echo "== packaging CFN to S3..."
aws cloudformation package \
  --template-file $CFN_PATH \
  --s3-bucket $BUCKET \
  --s3-prefix cicd-package \
  --region $REGION \
  --output-template-file "$PACKAGED_PATH"

aws cloudformation deploy \  
  --stack-name $STACK_NAME \
  --s3-bucket $BUCKET \
  --s3-prefix cicd \
  --region $REGION \
  --template-file "$PACKAGED_PATH" \
  --no-execute-changeset \
  --tags group=cruddur-cicd \
  --parameter-overrides $PARAMETERS \
  --capabilities CAPABILITY_NAMED_IAM
```


“The aws cloudformation package command is used to transform and package a CloudFormation template before deploying it. It prepares the template for deployment by uploading any local artifacts referenced in the template to an Amazon S3 bucket. This is necessary because CloudFormation has a limit on the template size, so large templates or templates with inline code may need to be packaged separately."

This is why we defined a new variable PACKAGED_PATH. For this, we added a new folder to our root directory called tmp, then updated our .gitignore file to include it and everything in it with a wildcard:

```
docker/**/*
frontend-react-js/build/*
*.env
node_modules
.aws-sam
build.toml
tmp/*
```
This pathing was added as our script will now generate a new packaged-template.yaml file when we run it. Just as ChatGPT told us to "package a CloudFormation template before deploying it."

We attempt our cicd-deploy script again, receiving the same message as before. Andrew notes that the error isn't an error and in fact is a warning (as noted by the code "W3002"), so we comment out the line in our script that stops the execution if any part fails.

Then we deploy again. We still receive the warning, but the changeset deploys.


We know this worked, because we now have a packaged-template.yaml file in the tmp directory we created:


We open the packaged-template.yaml to see what it generated for the TemplateUrl property of the stack and it generated a .template file in the codepipeline- bucket with a path:


From CloudFormation, we execute the changeset. When I execute the changeset, I receive an error whereas Andrew does not. My error:


This is because my template.yaml is passing a property for Source configuration that's unrecognized. After sifting through the code, I find the error and adjust it. I had declared Branchname instead of BranchName.


After fixing the code, I again run our cicd-deploy script, then execute the changeset from CloudFormation. This time, the stack is created successfully.


We head over to CodePipeline in AWS, then review our pipeline. It failed on the first attempt to execute.


Andrew guides us over to Settings > Connections to show us this is due to the connection always being in a Pending status when first deployed.


After we select the connection, then click “Update pending connection”, our connection becomes available.


This should complete our CICD layer. From here it’s time to move onto implementing the frontend service, deploying it to CloudFront using S3 buckets.









# Frontend Service
From our workspace, we make a new folder named frontend in our ./aws/cfn directory. In the frontend folder, we create our template.yaml and config.toml files. We start with the config.toml

```yaml
[deploy]
bucket = 'cfn-artifacts-1'
region = 'us-east-1'
stack_name = 'CrdFrontend'
```

Then starting working on the frontend template.yaml. We start by adding our description, noting what we're defining in the template:

```
AWSTemplateFormatVersion: 2010-09-09
Description: | 
  - CloudFront Distribution
  - S3 Bucket for www.
  - S3 Bucket for root domain
  - Bucket Policy
Parameters: 
Resources: 
```

We start defining our buckets that we need:

```yaml
  WWWBucket:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket.html
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref WwwBucketName 
  RootBucket: 
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket.html
    Type: AWS::S3::Bucket
    #DeletionPolicy: Retain
    Properties:
      BucketName: !Ref RootBucketName
```

We also add these paremeters we’re referencing here:

```
Parameters: 
  WwwBucketName:
    Type: String
  RootBucketName:
    Type: String
```

Then we work through the properties for the buckets:

```
  WWWBucket:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket.html
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref WwwBucketName 
      WebsiteConfiguration: 
        RedirectAllRequestsTo:
          HostName: !Ref RootBucketName  
  RootBucket: 
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket.html
    Type: AWS::S3::Bucket
    #DeletionPolicy: Retain
    Properties:
      BucketName: !Ref RootBucketName    
      WebsiteConfiguration: 
        IndexDocument: index.html
        ErrorDocument: error.html
```

The WWWBucket is configured to redirect all requests to the RootBucket. The RootBucket has public access enabled and is configured as a website with an index document and an error document.

We next start implementing the CloudFront Distribution:

```
  Distribution:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudfront-distribution.html#aws-resource-cloudfront-distribution
    Type: AWS::CloudFront::Distribution
    Properties:
      DistributionConfig:
        Aliases:
          - gooddesignsolutions.in
          - www.gooddesignsolutions.in
        Comment: Frontend React Js for Cruddur
        Enabled: true
        HttpVersion: http2and3
        DefaultRootObject: index.html                
        Origins:
          - DomainName: !GetAtt RootBucket.DomainName
            Id: RootBucketOrigin
            S3OriginConfig: {}
        DefaultCacheBehavior:
          TargetOriginId: RootBucketOrigin
          ForwardedValues:
            QueryString: false
            Cookies:
              Forward: none
          ViewerProtocolPolicy: redirect-to-https
        ViewerCertificate:
          AcmCertificateArn: !Ref CertificateArn
          SslSupportMethod: sni-only
```

Let’s break down these properties:

Aliases: Specifies the domain names (CNAMEs) associated with the CloudFront distribution. Requests made to the domain names provided will be routed to the CloudFront distribution.

HttpVersion: fairly self explanatory, but this property specifies the support HTTP versions for the CloudFront distribution

DefaultRootObject: When a request is made to the distribution's domain name, CloudFront will return the specified object, in our case, index.html

Origins: Specifies the origins (sources) from which CloudFront fetches content. An origin can be an S3 bucket, an EC2 instance, or an Elastic Load Balancer, among others.

DefaultCacheBehavior: Configures the default cache behavior for the CloudFront distribution, which determines how CloudFront caches and forwards requests to the origin when there is no specific cache behavior matching the requested URL path.

ViewerCertificate: Configures the SSL/TLS certificate for the CloudFront distribution, enabling HTTPS support.

We also reference the CertificateArn from our cluster layer, so we add this as a parameter:

```
Parameters: 
  CertificateArn:
    Type: String
```
From here, we need to add our bucket policy. This will add permissions for the root bucket, as all requests to the WWWBucket are forwarded to the RootBucket:

```
  RootBucketPolicy:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-policy.html
    Type: AWS::S3::BucketPolicy
    Properties: 
      Bucket: !Ref RootBucket
      PolicyDocument:
        Statement: 
          - Action:
              - 's3:GetObject'
            Effect: Allow
            Resource: !Sub 'arn:aws:s3:::${RootBucket}/*'
            Principal: '*'
```

All that should be left to add to our frontend template.yaml is a record set for each bucket. That will define the DNS records within Route53 for us.

```
  RootBucketDomain:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-route53-recordset.html
    Type: AWS::Route53::RecordSet
    Properties: 
      HostedZoneName: !Sub ${RootBucketName}.
      Name: !Sub ${RootBucketName}.
      Type: A
      AliasTarget:
        DNSName: !GetAtt CloudFrontDistribution.DomainName
        # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-route53-aliastarget.html#cfn-route53-aliastarget-hostedzoneid
        # Specify Z2FDTNDATAQYW2. This is always the hosted zone ID when you create an alias record that routes traffic to a CloudFront distribution.
        HostedZoneId: Z2FDTNDATAQYW2
  WwwBucketDomain:
    # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-route53-recordset.html
    Type: AWS::Route53::RecordSet
    Properties: 
      HostedZoneName: !Sub ${RootBucketName}.
      Name: !Sub ${WwwBucketName}.
      Type: A
      AliasTarget:
        DNSName: !GetAtt CloudFrontDistribution.DomainName
        # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-route53-aliastarget.html#cfn-route53-aliastarget-hostedzoneid
        # Specify Z2FDTNDATAQYW2. This is always the hosted zone ID when you create an alias record that routes traffic to a CloudFront distribution.
        HostedZoneId: Z2FDTNDATAQYW2 
```

A little more on these properties:

HostedZoneName: The domain name associated with the Route 53 hosted zone where the record will be created. It is a string value that can be a domain name or a fully qualified domain name (FQDN).

Name: The fully qualified domain name (FQDN) for the record.

Type: The record type, which is set to A in this case. It can be one of the standard record types such as A, AAAA, CNAME, MX, TXT, etc.

AliasTarget: Specifies an alias target to route traffic to. It allows you to route traffic to an AWS resource using an alias instead of specifying explicit IP addresses. There's 2 additional properties of the AliasTarget:

DNSName: Specifies the DNS name of the target resource to which the alias will point.
HostedZoneId: Specifies the hosted zone ID of the target resource. In this case, we've set it to Z2FDTNDATAQYW2, which is the hosted zone ID for CloudFront distributions. This value is always used when creating an alias record that routes traffic to a CloudFront distribution.
We also take this time to add our parameters to our config.toml:

```
[deploy]
bucket = 'cfn-artifacts-1'
region = 'us-east-1'
stack_name = 'CrdFrontend'

[parameters]
CertificateArn = 'arn:aws:acm:us-east-1:999999999999:certificate/9e966975-36c4-4808-ad6a-d20172eef714'
WwwBucketName = 'www.gooddesignsolutions.in'
RootBucketName = 'gooddesignsolutions.in'
```

At this point we should be ready to deploy, so in the ./bin/cfn directory, we create a new file named frontend-deploy. Before we even begin writing the script, Andrew wants us to know that we're using the scripts to provision the infrastructure, not deploy. To make it less confusing, we renamed all of our
scripts in the ./bin/cfn directory, removing the -deploy from the name.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/b11517ba-6ab7-4b3c-a131-c3b84d5813ac)

We copy over the script from our now named cluster script to our frontend script. As always, we adjust the CFN_PATH and CONFIG_PATH to reflect the pathing changes.

```
#! /usr/bin/env bash
set -e #stop the execution of the script if it fails

CFN_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/frontend/template.yaml"
CONFIG_PATH="/workspace/aws-bootcamp-cruddur-2023/aws/cfn/frontend/config.toml"

cfn-lint $CFN_PATH 

BUCKET=$(cfn-toml key deploy.bucket -t $CONFIG_PATH)
REGION=$(cfn-toml key deploy.region -t $CONFIG_PATH)
STACK_NAME=$(cfn-toml key deploy.stack_name -t $CONFIG_PATH)
PARAMETERS=$(cfn-toml params v2 -t $CONFIG_PATH)

aws cloudformation deploy \
    --stack-name $STACK_NAME \
    --s3-bucket $BUCKET \
    --s3-prefix frontend \
    --region $REGION \
    --template-file $CFN_PATH \
    --no-execute-changeset \
    --tags group="cruddur-frontend" \
    --parameter-overrides $PARAMETERS \
    --capabilities CAPABILITY_NAMED_IAM
```

We make the file executable with a chmod command in the terminal, then run the frontend script.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/0e0c5a90-5e76-48b6-972e-864efa82e404)


We update the RecordSet property DNSName which falls under the AliasTarget property itself. The !GetAtt function is referencing the wrong distribution name:

      AliasTarget:
        DNSName: !GetAtt Distribution.DomainName
We update this for both RecordSet resources. After we make adjustments to the code, we attempt to provision the stack again and it creates a changeset successfully. Andrew notes before we execute it though, our template.yaml is going to generate an A record for our root domain, so we must remove the existing one from Route53 first so CloudFormation doesn't error out.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/a34c62a2-659f-40fa-b656-2278667dfc9c)

From here, we head back over to CloudFormation. We execute the changeset and get a CREATE_FAILED error.

The error indicates we do not have permissions to API: s3:PutBucketPolicy. After going through the CFN documentation, we found we needed to set a property on our RootBucket.

![image](https://github.com/bhanumalhotra123/aws-bootcamp-cruddur-2023/assets/144083659/cb28ef0c-ab4c-43b7-abfe-f2d210710dc1)

When BlockPublicPolicy is set to false, it means that the bucket policy can allow public access to the objects in the bucket. By default, S3 buckets are private and do not allow public access.

We delete the stack from CloudFormation and try our frontend script again. The changeset is created, so we head over to CloudFormation and execute it. After about 20 minutes, it creates successfully.





